{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOhTkWkMaJJr",
        "outputId": "4dce40da-216f-43ee-887d-859b7af7a12a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (1.39.3)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.7.0)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: PyCryptodome in /usr/local/lib/python3.11/dist-packages (3.23.0)\n",
            "Requirement already satisfied: qdrant-client in /usr/local/lib/python3.11/dist-packages (1.14.3)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.46.1)\n",
            "Requirement already satisfied: botocore<1.40.0,>=1.39.3 in /usr/local/lib/python3.11/dist-packages (from boto3) (1.39.3)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3) (0.13.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (1.73.1)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.10.1)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (5.29.5)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.11.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.4.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.45.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.40.0,>=1.39.3->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.40.0,>=1.39.3->boto3) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting pdfminer.six\n",
            "  Using cached pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement localtunnel (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for localtunnel\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "/tmp/ipython-input-3-3628888697.py:39: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
            "  client.recreate_collection(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "!pip install boto3 faiss-cpu sentence-transformers transformers accelerate pypdf PyPDF2 PyCryptodome qdrant-client streamlit\n",
        "!pip install nltk pdfminer.six scikit-learn localtunnel\n",
        "\n",
        "import io\n",
        "import os\n",
        "import uuid\n",
        "import boto3\n",
        "import nltk\n",
        "import string\n",
        "from PyPDF2 import PdfReader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import Distance, VectorParams, PointStruct, FieldCondition, Filter, MatchValue\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from google.colab import userdata\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "AWS_ACCESS_KEY = userdata.get(\"AWS_ACCESS_KEY\")\n",
        "AWS_SECRET_KEY = userdata.get(\"AWS_SECRET_KEY\")\n",
        "S3_BUCKET = \"rag-vector-db-poc\"\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "\n",
        "s3 = boto3.client(\n",
        "    's3',\n",
        "    aws_access_key_id=AWS_ACCESS_KEY,\n",
        "    aws_secret_access_key=AWS_SECRET_KEY\n",
        ")\n",
        "\n",
        "QDRANT_HOST = \"34.228.56.127\"\n",
        "QDRANT_PORT = 6333\n",
        "COLLECTION = \"docs_chunks\"\n",
        "\n",
        "client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT, timeout=30.0)\n",
        "\n",
        "client.recreate_collection(\n",
        "    collection_name=COLLECTION,\n",
        "    vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8fbb0099edfc4ba9bf3d396ff63fdee4",
            "80adcfc69f974d249dcc72828a45d41c",
            "064adf7732fd48c4a9984c4aa5476c35",
            "b0ae3ca6f66a49c59ecfb31b974c3dff",
            "df35626a32274290b233eed748c56a08",
            "6fa320b89fef4b939ed7087dfa69e841",
            "7c37effbe14645b3b5f099873c09c0de",
            "fe8241a42eb34deaa27b286b947656cf",
            "21bfb45891c8412bac1535cb85652c82",
            "fde048cc7f5a46be917a4e491256ac2f",
            "5e53585248774ddbb1139d62bf26e22f",
            "28f9f358b827478abd19ab850d733b48",
            "075eda04743748579d2ae353863e38ef",
            "68845fac2626420e89ec39226de33525",
            "e3631036bc034f26874cad147c9bb738",
            "b13313670cce43d6aa2a69efb844285a",
            "6c0a8e836a864502abfa49cb2156deba",
            "578d211df9fb47bb98bcb19d0397eeee",
            "1e19cd05cbb142d4873a206a30e929de",
            "c97fe14fbc3e4cffbfd94b95ed78148b",
            "50bf1f94336849df821cdca00fec3eec",
            "256b2ed0925c47aabcbccdc444265ede",
            "7d628c242a43459ba7f7e2694a54dfb7",
            "11004b66a7d84e7ab2cf66fc45bce8b3",
            "73114c4a115b4ff283903126aa5f5f1e",
            "4b665333955047388b1014d78c09dace",
            "3ba00ba9adb34357897803dbd5912e0e",
            "f112e797094046ab85572946c167983e",
            "f3432e8539f7457e8e554b3f51c74a7e",
            "14f42cbac9eb4e24b57ae0f4ed6a3df4",
            "843f5d88537547088deb2389e8c0d8c5",
            "e23c77c24f2841a58e586d16dae38d26",
            "06be448d605e4b07ab6c822f24ea27a2",
            "f36ff66f2f664a65b427cce1e23d0f14",
            "820a460ae005474bb3f508f721b25e5f",
            "cf3fb69ffee3424ea058665e1758861b",
            "584d12678b794116bc781bc1885951fd",
            "39c341dd244d477f93479b756a52eb81",
            "a1bf12fb765840219cc655c508e47a41",
            "4066722238f74af088d67977dec41e2a",
            "f6c0927d64914e43b8014e3acd4ce4b3",
            "6f703951870a4d4581f58cb98ba38766",
            "f25cc24bec584e32bb3f64330a158950",
            "90aa47215a4042b28f89f29a37bc781c",
            "87ccbc78d61f479b805a61d00d6f6c12",
            "ceecc08123934525a786fdaecc909f27",
            "455bddad12cb4d328476cf89ad29bc86",
            "553ec0f51b2f4515ab80762a88386319",
            "ba8865c33f154594836d890e00e833c2",
            "894b0c5d6336457780479d446274bd94",
            "0a49dc8ee82246c4bc133b2c0b3339a9",
            "83ff4468a6854ae3bedd8be0052bcc24",
            "6011f247441c4c85a50b0f71d15b70be",
            "d8ea60fc89974be2ae8e0c7d41c3b1d6",
            "6dd69386a9ac440fb4101ffb03c5247c",
            "795eca22e31648d8a04df0daa4b05a7a",
            "cee22c0ee94047339024378ba7371684",
            "2038bdf2485d46baae2f72f5017cda5a",
            "5b2c35b463534a7fae3a4ad957f20ebf",
            "5bc1482daa2441e8b9152080ac56b1da",
            "7a0fa4cc583948afa85eb97614bcef57",
            "180c71dd5bec4e46b82648b390532a6b",
            "b45e41764a054d17a7cfeb1f4e038a85",
            "4a78048c2d6c4e818478376486200e25",
            "555bd020baea417e9b711411282fd9e2",
            "eb32c83e4fa64dab87e93be128bb6f47",
            "91efd31fec3f484a8ca9b27c83943314",
            "22eeb8ce585c4563be480dde038e98f9",
            "298547ba098a4a999651f4867c0cce74",
            "45641ec6e9d742198b1be83eeadcac30",
            "b94aeed5822c450bb6be9257b16a8cc4",
            "6d7f4689607e4a678cae270de14e4010",
            "878698308fd14adfad1dd00265502074",
            "b113a9be42fd4044b094ad463def47b2",
            "8ec6dfb062144a43af3d72901795a0e9",
            "85a756d65f844e53b370a43f8fab5efd",
            "0de0a9a8f30540c3a7ce8a3e7f302cbd",
            "334ff0f080714157a9a75ac40d6444fc",
            "575c32a798bd40959531804c0d9b4d19",
            "1337fb4dac504af0bff4652935c23454",
            "3f99f58c47794161907c36b7177f9649",
            "2cf8f0f84d8247e8aa88d8a9bc62b175",
            "df3d109cac1b47d6962bad51b125dcb0",
            "ce813e19c9ef4c93aabb799a6393b941",
            "0e0515190dd541b684c6f3559e93aa5f",
            "532d9fbfa6044a46a50c9625d68fd602",
            "757672ff1224495bb7d381d0a6d61d0b",
            "2995a6cf0c224ab39bb1be8ad8c858d4",
            "4787153f2a954929b1bbf2745fc35632",
            "fb8db9b34d0141a39bca79d3bf44691d",
            "ed4ff0f10f14450a8b77295fd08947d3",
            "28eda06ea6f147399725add40e161b2f",
            "cf1692b8c17a4f06b1d4c353c69f58bc",
            "f3fd07f6a1074bda9cb05b90d0b44638",
            "2472ed2b530a4f9a8a27c08ce8a72093",
            "8fc9199048ff40e1aac99a08010a84d9",
            "d84b83f8b51b4fc89647097dc138a9af",
            "24c5f93dee7c41f1b32a06a94ab83ce7",
            "5793332c630d4ae09587f4b388304fff",
            "755efbbb56f84b56a8bed549a1bfd46c",
            "305b40f094d34760ae3b236508d8bc4d",
            "0ac6970cd76a4992a83023c8f0aa6793",
            "368c1fa641d6441bbbec5a1df45690a8",
            "edd92632c0a24631ab0fc2bdaca61861",
            "0e2d7488ab6648b0af1c86b84b31aac4",
            "06bbf254cd6a44fbb628051be546582a",
            "3069b3cad5594f4aa50f659b092f2998",
            "17eec0c390094d9282e985e26dc67800",
            "0086269d332e4eb7b9ce2471d995ea80",
            "3dd9dc336f94457085562163282a77b0",
            "ae2e344dc41d47d180e07948fa0a5f19",
            "25394831ad0d4e2bb96c63b4c3041f22",
            "2d63d731489d4d6ea3f950b216ed3172",
            "d17758c7e33249a0bb77a2347c60f814",
            "1f37a0decc64481aaa87efe732e20412",
            "ec8c1d6eafa04290ab6919d23f68ca8f",
            "8fece7384d7349229bf0ae48f28cd970",
            "c4aa28ea041140fc9ffbdc9f4e2ca3ba",
            "28dc0b070524423997ac3209b3a64caa",
            "2bc6d465e2914c3486b93414f2385156",
            "ab98f14d9730407e832404fb8b52fe8e",
            "c2b57082e9d04b898fac4dbb27dda531",
            "2bb29c3b6eec48259442159c60641db8",
            "47548bcb2380443d8cef30c7f982785b",
            "5f5796f661e24fe59e883df6efcb7424",
            "f665b6ca2ad24d4a8c1afdc6d8982085",
            "05d1c714029049b2be2f2e5fe7f7b61b",
            "0900a283f8344f2eb147fa1520862883",
            "a8cd211a70434064926219ae223736d2",
            "92eb9d6035b044e2947a6f7f5fd6c6a1",
            "5dcd70cb81d04c2a99d16efdd5c9a746",
            "f3b2ae76ecdc4de0992a61adccbaf603",
            "feb2e6afa7494f3389c95f8f019de904",
            "5c08b1cdeced4fdb987f2fdb5ba05fb2",
            "9fca02d91ef7446585da4aa6c68e1d98",
            "8a8fcf087e934e4e9a00a8de5089658b",
            "7f9b49e381f446b79d051e5f3a3f67f5",
            "fd84414920604f1194215c3db63d0605",
            "103fee5e797d4aac83a4523d99a3a155",
            "4207997a38b344c0b4f17dd527fb5f22",
            "e0173f36f61c47658c0ea8ae2ba75835",
            "71430a55b4ae494b91b1ddcbfa080d42",
            "6711d2c5bd804877b18ba99584da9116",
            "7ffcc6e266af4cd5ac1e5ad2a1ceeb2e",
            "08b79ff8ba8b4d15a9c3bf1a611eafde",
            "dfd6c3a387324751b53532c575b6b37c",
            "0ed45a1dfd5047038f11005deb9c36be",
            "11de4a75fec6444aa24a5c44708e4c76",
            "32f04950e5fa49b59c3848e7bcf62c7c",
            "0cf0b91839b841a5ab20a1aba68ce3ee",
            "100380cb8f534310901078fc458e345e",
            "ebc3ec2bb5a74c1297164b5762e84b6d",
            "e9c95a63b33b490ca66a29f770a726b2",
            "63fddacf860c43dda5b76e63321d165b"
          ]
        },
        "id": "-QeAOw3ae4BB",
        "outputId": "438d66c9-6023-443f-cf6e-1d79e5b9aa0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ Processing: Arrakis.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fbb0099edfc4ba9bf3d396ff63fdee4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Uploaded: Arrakis.pdf\n",
            "üìÑ Processing: Crash_Consistency.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28f9f358b827478abd19ab850d733b48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Uploaded: Crash_Consistency.pdf\n",
            "üìÑ Processing: Demikernel.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d628c242a43459ba7f7e2694a54dfb7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Uploaded: Demikernel.pdf\n",
            "üìÑ Processing: Exokernel.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f36ff66f2f664a65b427cce1e23d0f14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Uploaded: Exokernel.pdf\n",
            "üìÑ Processing: FFS_Unix.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87ccbc78d61f479b805a61d00d6f6c12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Uploaded: FFS_Unix.pdf\n",
            "üìÑ Processing: FireCracker.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "795eca22e31648d8a04df0daa4b05a7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Uploaded: FireCracker.pdf\n",
            "üìÑ Processing: HeMem.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91efd31fec3f484a8ca9b27c83943314"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Uploaded: HeMem.pdf\n",
            "üìÑ Processing: LogFS.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "334ff0f080714157a9a75ac40d6444fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Uploaded: LogFS.pdf\n",
            "üìÑ Processing: Pond.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4787153f2a954929b1bbf2745fc35632"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Uploaded: Pond.pdf\n",
            "üìÑ Processing: Unix.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "755efbbb56f84b56a8bed549a1bfd46c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Uploaded: Unix.pdf\n",
            "üìÑ Processing: ghOSt.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae2e344dc41d47d180e07948fa0a5f19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Uploaded: ghOSt.pdf\n",
            "üìÑ Processing: navarro.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2b57082e9d04b898fac4dbb27dda531"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Uploaded: navarro.pdf\n",
            "üìÑ Processing: scheduler-activations.pdf\n",
            "‚ùå Failed: scheduler-activations.pdf\n",
            "Missed the stop code in LZWDecode!\n",
            "üìÑ Processing: the_linux_schedule_a_decade_of_wasted_cores.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "feb2e6afa7494f3389c95f8f019de904"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Uploaded: the_linux_schedule_a_decade_of_wasted_cores.pdf\n",
            "üìÑ Processing: xen_and_the_art_of_virtualization.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ffcc6e266af4cd5ac1e5ad2a1ceeb2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Uploaded: xen_and_the_art_of_virtualization.pdf\n"
          ]
        }
      ],
      "source": [
        "# === S3 Utilities ===\n",
        "def list_text_and_pdf_keys(bucket, prefix=\"\"):\n",
        "    keys = []\n",
        "    paginator = s3.get_paginator(\"list_objects_v2\")\n",
        "    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
        "        for obj in page.get(\"Contents\", []):\n",
        "            key = obj[\"Key\"]\n",
        "            if key.endswith(\".pdf\") or key.endswith(\".txt\"):\n",
        "                keys.append(key)\n",
        "    return keys\n",
        "\n",
        "def download_file_from_s3(bucket, key):\n",
        "    response = s3.get_object(Bucket=bucket, Key=key)\n",
        "    return io.BytesIO(response['Body'].read())\n",
        "\n",
        "# === Text Extraction ===\n",
        "def extract_text_from_pdf(pdf_io):\n",
        "    reader = PdfReader(pdf_io)\n",
        "    return \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
        "\n",
        "def extract_text_from_txt(txt_io):\n",
        "    return txt_io.read().decode(\"utf-8\")\n",
        "\n",
        "# === Chunking ===\n",
        "def chunk_paragraphs(text, s3_path, chunk_token_limit=500):\n",
        "    # Extract the S3 key path (excluding bucket name)\n",
        "    key_path = s3_path.replace(\"s3://\", \"\").split(\"/\", 1)[1]  # get \"finance/2023/report.pdf\"\n",
        "    department = key_path.split(\"/\")[0] if \"/\" in key_path else \"root\"\n",
        "    file_name = os.path.basename(s3_path)\n",
        "\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks, current_chunk = [], []\n",
        "    token_count = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = sentence.split()\n",
        "        token_len = len(tokens)\n",
        "        if token_count + token_len > chunk_token_limit:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            current_chunk = []\n",
        "            token_count = 0\n",
        "        current_chunk.append(sentence)\n",
        "        token_count += token_len\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    return [\n",
        "        {\n",
        "            \"text\": chunk,\n",
        "            \"s3_path\": s3_path,\n",
        "            \"file_name\": file_name,\n",
        "            \"chunk_id\": f\"{s3_path}_{i}\",\n",
        "            \"chunk_index\": i,\n",
        "            \"token_count\": len(chunk.split()),\n",
        "            \"department\": department,  # ‚úÖ renamed here\n",
        "            \"top_keywords\": extract_top_keywords(chunk)\n",
        "        }\n",
        "        for i, chunk in enumerate(chunks)\n",
        "    ]\n",
        "\n",
        "\n",
        "# === Keyword Extraction ===\n",
        "def extract_top_keywords(text, top_n=5):\n",
        "    try:\n",
        "        vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=top_n)\n",
        "        X = vectorizer.fit_transform([text])\n",
        "        scores = X.toarray().flatten()\n",
        "        return {word: round(score, 4) for word, score in zip(vectorizer.get_feature_names_out(), scores)}\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "# === Embedding & Upload ===\n",
        "def embed_chunks(chunks):\n",
        "    texts = [c[\"text\"] for c in chunks]\n",
        "    return embed_model.encode(texts, show_progress_bar=True)\n",
        "\n",
        "def upload_chunks_to_qdrant(chunks, embeddings):\n",
        "    points = [\n",
        "        PointStruct(\n",
        "            id=str(uuid.uuid4()),\n",
        "            vector=embedding,\n",
        "            payload=chunk\n",
        "        )\n",
        "        for chunk, embedding in zip(chunks, embeddings)\n",
        "    ]\n",
        "    client.upsert(collection_name=COLLECTION, points=points)\n",
        "\n",
        "# === Orchestration ===\n",
        "def process_and_upload_files(bucket, keys):\n",
        "    for key in keys:\n",
        "        try:\n",
        "            print(f\"üìÑ Processing: {key}\")\n",
        "            file_io = download_file_from_s3(bucket, key)\n",
        "\n",
        "            if key.endswith(\".pdf\"):\n",
        "                text = extract_text_from_pdf(file_io)\n",
        "            elif key.endswith(\".txt\"):\n",
        "                text = extract_text_from_txt(file_io)\n",
        "            else:\n",
        "                print(f\"Skipping unsupported file type: {key}\")\n",
        "                continue\n",
        "\n",
        "            chunks = chunk_paragraphs(text, s3_path=f\"s3://{bucket}/{key}\")\n",
        "            embeddings = embed_chunks(chunks)\n",
        "            upload_chunks_to_qdrant(chunks, embeddings)\n",
        "            print(f\"‚úÖ Uploaded: {key}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed: {key}\\n{e}\")\n",
        "\n",
        "# === Run ===\n",
        "file_keys = list_text_and_pdf_keys(S3_BUCKET)\n",
        "process_and_upload_files(S3_BUCKET, file_keys)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "def compute_overlap_score(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "def evaluate_rag_query(query, expected_sources=None, expected_answer=None, k=5):\n",
        "    start = time.time()\n",
        "    chunks = search_qdrant(query, k)\n",
        "    prompt, refs = build_prompt(query, chunks)\n",
        "\n",
        "    # LLM Call\n",
        "    response = azure_client.chat.completions.create(\n",
        "        model=AZURE_DEPLOYMENT_NAME,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant...\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].message.content.strip()\n",
        "    latency = round((time.time() - start) * 1000, 2)\n",
        "\n",
        "    # Monitoring & Logging\n",
        "    retrieved_sources = list(refs.values())\n",
        "    top_chunks = chunks\n",
        "    prompt_tokens = getattr(response.usage, \"prompt_tokens\", None)\n",
        "    completion_tokens = getattr(response.usage, \"completion_tokens\", None)\n",
        "\n",
        "    # Evaluation Metrics\n",
        "    precision = recall = mrr = None\n",
        "    hallucination_rate = 0\n",
        "    overlap_score = None\n",
        "\n",
        "    if expected_sources:\n",
        "        retrieved_set = set(retrieved_sources)\n",
        "        relevant_set = set(expected_sources)\n",
        "        true_positives = len(retrieved_set & relevant_set)\n",
        "        precision = true_positives / len(retrieved_set) if retrieved_set else 0\n",
        "        recall = true_positives / len(relevant_set) if relevant_set else 0\n",
        "        for i, s in enumerate(retrieved_sources):\n",
        "            if s in relevant_set:\n",
        "                mrr = 1 / (i + 1)\n",
        "                break\n",
        "        else:\n",
        "            mrr = 0\n",
        "\n",
        "    if expected_answer:\n",
        "        overlap_score = compute_overlap_score(answer, expected_answer)\n",
        "\n",
        "    query_eval = {\n",
        "        \"query\": query,\n",
        "        \"answer\": answer,\n",
        "        \"expected_answer\": expected_answer,\n",
        "        \"expected_sources\": expected_sources,\n",
        "        \"retrieved_sources\": retrieved_sources,\n",
        "        \"precision@k\": precision,\n",
        "        \"recall@k\": recall,\n",
        "        \"mrr@k\": mrr,\n",
        "        \"overlap_score\": overlap_score,\n",
        "        \"prompt_tokens\": prompt_tokens,\n",
        "        \"completion_tokens\": completion_tokens,\n",
        "        \"latency_ms\": latency,\n",
        "        \"citations_used\": len(refs),\n",
        "        \"top_chunks\": top_chunks,\n",
        "        \"errors\": [],\n",
        "    }\n",
        "\n",
        "    monitoring[\"query_log\"].append(query_eval)\n",
        "    for src in retrieved_sources:\n",
        "        monitoring[\"access_count\"][src] += 1\n",
        "    monitoring[\"latencies\"].append(latency)\n",
        "\n",
        "    return query_eval\n"
      ],
      "metadata": {
        "id": "syDyBLellLym"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid, time\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import Distance, VectorParams, PointStruct, Filter, FieldCondition, MatchValue\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "# Azure OpenAI Config (replace with actual values)\n",
        "AZURE_OPENAI_ENDPOINT = \"https://ironclad-openai-001.openai.azure.com/\"\n",
        "AZURE_OPENAI_API_KEY = \"936856630b764210913d9a8fd6c8212b\"\n",
        "AZURE_DEPLOYMENT_NAME = \"gpt-4o\"\n",
        "\n",
        "azure_client = AzureOpenAI(\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        "    api_version=\"2023-05-15\",\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
        ")\n",
        "\n",
        "# ------------------- QDRANT -------------------\n",
        "client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT, timeout=120)\n",
        "\n",
        "# ------------------- MONITORING -------------------\n",
        "monitoring = {\n",
        "    \"access_count\": defaultdict(int),\n",
        "    \"latencies\": [],\n",
        "    \"query_log\": []\n",
        "}\n",
        "\n",
        "# ------------------- RAG FUNCTIONS -------------------\n",
        "def search_qdrant(query, k=5):\n",
        "    vec = embed_model.encode([query])[0]\n",
        "\n",
        "    results = client.query_points(\n",
        "        collection_name=COLLECTION,\n",
        "        query=vec,\n",
        "        limit=k,\n",
        "        with_payload=True,\n",
        "        timeout=120\n",
        "    )\n",
        "\n",
        "    metadata_list = []\n",
        "    for point in results.points:\n",
        "        metadata = {\n",
        "            \"score\": point.score,\n",
        "            \"text\": point.payload.get(\"text\", \"\"),\n",
        "            \"s3_path\": point.payload.get(\"s3_path\", \"\"),\n",
        "            \"file_name\": point.payload.get(\"file_name\", \"\"),\n",
        "            \"department\": point.payload.get(\"department\", \"\"),\n",
        "            \"top_keywords\": point.payload.get(\"top_keywords\", {}),\n",
        "        }\n",
        "        metadata_list.append(metadata)\n",
        "    return metadata_list\n",
        "\n",
        "def build_prompt(query, top_chunks):\n",
        "    context = \"\"\n",
        "    source_refs = {}\n",
        "\n",
        "    for i, chunk in enumerate(top_chunks):\n",
        "        ref = f\"[{i+1}]\"\n",
        "        source = chunk.get(\"s3_path\", \"unknown\")\n",
        "        context += f\"{ref} ({source}):\\n{chunk['text']}\\n\\n\"\n",
        "        source_refs[ref] = source\n",
        "\n",
        "    prompt = f\"\"\"You are a helpful assistant. Use only the following context to answer the question.\n",
        "Cite sources using [1], [2], etc., based only on the exact chunks below. Do not make up citations. Do not include sources not explicitly mentioned.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "    return prompt, source_refs\n",
        "\n",
        "def rag_query(query, k=5):\n",
        "    start = time.time()\n",
        "    chunks = search_qdrant(query, k)\n",
        "    prompt, refs = build_prompt(query, chunks)\n",
        "\n",
        "    response = azure_client.chat.completions.create(\n",
        "        model=AZURE_DEPLOYMENT_NAME,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use only the following context to answer the question. Cite sources using [1], [2], etc., based only on the exact chunks below. Do not make up citations. Do not include sources not explicitly mentioned.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].message.content.strip()\n",
        "    latency = round((time.time() - start) * 1000, 2)\n",
        "\n",
        "    for ref in refs.values():\n",
        "        monitoring[\"access_count\"][ref] += 1\n",
        "    monitoring[\"latencies\"].append(latency)\n",
        "    monitoring[\"query_log\"].append({\n",
        "        \"query\": query,\n",
        "        \"sources\": list(refs.values()),\n",
        "        \"latency_ms\": latency\n",
        "    })\n",
        "\n",
        "    return answer, refs, latency, chunks\n",
        "\n",
        "# ------------------- MAIN SCRIPT -------------------\n",
        "\n",
        "questions = [\n",
        "    \"How does Arrakis ensure security and isolation for applications that have direct access to hardware devices, bypassing traditional kernel mediation?\",\n",
        "    \"What are the key hardware support features required to enable Arrakis's direct I/O access model, and how do these features impact hardware complexity and cost?\",\n",
        "    \"In what ways can the Arrakis architecture be extended or adapted to virtualized environments and multi-tenant cloud data centers, and what challenges might arise in such contexts?\",\n",
        "    \"How does OptFS's approach to decoupling ordering and durability via osync() and dsync() primitives impact overall system performance and reliability?\",\n",
        "    \"In what ways does optimistic crash consistency differ from traditional journaling or soft updates methods, and what are its primary advantages and potential drawbacks?\",\n",
        "    \"How do the case studies with gedit and SQLite demonstrate the practical benefits and limitations of the proposed optimistic crash consistency techniques?\",\n",
        "    \"How does Demikernel achieve nanosecond-scale I/O processing overheads while maintaining portability across heterogeneous kernel-bypass devices?\",\n",
        "    \"In what ways does the PDPIX API improve programmability for ¬µs-scale datacenter systems compared to traditional POSIX or existing kernel-bypass APIs?\",\n",
        "    \"What challenges did the authors face when integrating networking (e.g., DPDK, RDMA) and storage (e.g., SPDK) libOSes in a single Demikernel datapath OS, and how were they addressed?\",\n",
        "    \"How does Pond balance the trade-off between latency sensitivity and DRAM savings when determining VM memory allocation, and what role do its machine learning models play in this process?\",\n",
        "    \"Given the increasing access latency with larger CXL memory pool sizes, what are the practical scalability limits of Pond's architecture, and how do these limits impact overall datacenter design?\",\n",
        "    \"How does Pond‚Äôs zNUMA approach differ from traditional NUMA memory management, and what mechanisms ensure performance remains consistent even with incorrect memory usage predictions?\",\n",
        "    \"How does HeMem's asynchronous sampling via PEBS compare in scalability and accuracy to traditional page table scanning for hot data identification, especially as memory capacity reaches terabyte scale?\",\n",
        "    \"Given HeMem‚Äôs user-space implementation and its reliance on userfaultfd and DMA migration, what are the potential challenges or limitations in extending it to support kernel-level memory or shared memory scenarios in multi-tenant cloud environments?\",\n",
        "    \"Considering that HeMem achieves significant reductions in NVM wear, what design principles can be abstracted and applied to emerging memory technologies (e.g., MRAM, ReRAM) with similar asymmetries in read/write performance or endurance?\",\n",
        "    \"What architectural and implementation choices enabled Firecracker to achieve both low overhead and strong isolation compared to traditional hypervisors like QEMU?\",\n",
        "    \"How does Firecracker‚Äôs design and integration with AWS Lambda enable fast function startup and efficient resource utilization at massive scale?\",\n",
        "    \"In what ways does Firecracker‚Äôs minimal device model and use of Rust for VMM development contribute to reducing the trusted computing base (TCB) and improving security?\",\n",
        "    \"What key design strategies did the authors implement to manage physical memory fragmentation and ensure sustained superpage performance under memory pressure?\",\n",
        "    \"How does the reservation-based allocation mechanism proposed in the paper differ from eager promotion or relocation-based superpage management strategies used in other operating systems like HP-UX or IRIX?\",\n",
        "    \"What are the primary trade-offs involved in the incremental promotion and speculative demotion of superpages, and how do these impact system performance and memory overhead?\",\n",
        "    \"What are the main advantages of using a log-structured file system (LFS) compared to traditional Unix file systems, especially in handling small file workloads?\",\n",
        "    \"How does Sprite LFS manage free space using segment cleaning, and what is the role of the cost-benefit policy in optimizing write performance?\",\n",
        "    \"In what ways does the crash recovery mechanism in Sprite LFS leverage the log structure to improve reliability and recovery time, and how does this differ from traditional file system recovery approaches?\"\n",
        "\n",
        "]\n",
        "\n",
        "for i,q in enumerate(questions):\n",
        "    print(f\"\\n========== QUESTION {i+1}: {q} ==========\\n\")\n",
        "    answer, refs, latency, retrieved_chunks = rag_query(q)\n",
        "\n",
        "    print(\"->> Answer:\\n\")\n",
        "    print(answer)\n",
        "\n",
        "    print(\"\\n->> Top 5 Retrieved Chunks:\\n\")\n",
        "    for i, chunk in enumerate(retrieved_chunks):\n",
        "        print(f\"[{i+1}] File: {chunk['file_name']}\")\n",
        "        print(f\"    Path: {chunk['s3_path']}\")\n",
        "        print(f\"    Department: {chunk.get('department', 'unknown')}\")\n",
        "        print(f\"    Text: {chunk['text'][:50].strip()}...\\n\")\n",
        "\n",
        "    print(f\"->>Latency: {latency} ms\")\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "\n",
        "# ------------------- SUMMARY -------------------\n",
        "\n",
        "print(\"\\n========== SUMMARY ==========\\n\")\n",
        "print(f\"Total Queries: {len(monitoring['query_log'])}\")\n",
        "if monitoring[\"latencies\"]:\n",
        "    print(f\"Average Latency: {np.mean(monitoring['latencies']):.2f} ms\")\n",
        "    print(\"\\nTop Accessed Sources:\")\n",
        "    top_sources = sorted(monitoring[\"access_count\"].items(), key=lambda x: x[1], reverse=True)\n",
        "    for src, count in top_sources:\n",
        "        print(f\"‚Ä¢ {src}: {count}x\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-H85x9FdtWx",
        "outputId": "6c5c5206-20f6-4e9e-cba7-123c79e01c0b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== QUESTION 1: How does Arrakis ensure security and isolation for applications that have direct access to hardware devices, bypassing traditional kernel mediation? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "Arrakis ensures security and isolation for applications with direct access to hardware devices by using device hardware to deliver I/O directly to a customized user-level library, without compromising process isolation. The Arrakis kernel operates in the control plane, configuring the hardware to limit application misbehavior. It achieves this by effectively isolating I/O operations, relying on hardware support for virtualization to present multiple instances of devices that are mapped to separate protection domains. This setup allows applications to conduct I/O through their protected virtual device instance without requiring kernel intervention, ensuring that security checks are integrated into the device's management interface accessible from the control plane [3], [4]. Additionally, Arrakis uses secure user-level networking and storage with a hardware-independent device model that captures the functionality required to implement data plane operations traditionally handled by the kernel [4].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: When\n",
            "choosing a replacement, we were looking for s...\n",
            "\n",
            "[2] File: Arrakis.pdf\n",
            "    Path: s3://rag-vector-db-poc/Arrakis.pdf\n",
            "    Department: root\n",
            "    Text: Nemesis [ 15] reduces\n",
            "shared components to provide...\n",
            "\n",
            "[3] File: Arrakis.pdf\n",
            "    Path: s3://rag-vector-db-poc/Arrakis.pdf\n",
            "    Department: root\n",
            "    Text: Applications interact\n",
            "with the system through a tr...\n",
            "\n",
            "[4] File: Arrakis.pdf\n",
            "    Path: s3://rag-vector-db-poc/Arrakis.pdf\n",
            "    Department: root\n",
            "    Text: ‚Ä¢Appropriate OS/hardware abstractions: Arrakis‚Äô ab...\n",
            "\n",
            "[5] File: Arrakis.pdf\n",
            "    Path: s3://rag-vector-db-poc/Arrakis.pdf\n",
            "    Department: root\n",
            "    Text: To mea-\n",
            "sure the expected VSIC performance with di...\n",
            "\n",
            "->>Latency: 1728.18 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 2: What are the key hardware support features required to enable Arrakis's direct I/O access model, and how do these features impact hardware complexity and cost? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "Arrakis's direct I/O access model relies heavily on hardware support features that allow applications to interact directly with hardware without kernel mediation, thereby maximizing performance and efficiency. These key hardware support features include:\n",
            "\n",
            "1. **Virtualization Support**: The hardware must be capable of presenting multiple instances of itself to the operating system and applications. This allows for each virtualized device instance to have unique memory-mapped register files, descriptor queues, and interrupts. Such support facilitates the mapping of each device instance to a separate protection domain, which is crucial for direct I/O operations without kernel intervention [2].\n",
            "\n",
            "2. **Management Interface**: Hardware should export a management interface accessible from the control plane. This interface is important for creating or destroying virtual device instances and associating them with network flows or storage areas. It also allows for the allocation of shared resources between different instances [2].\n",
            "\n",
            "3. **Optimized Network Stack Design**: Arrakis implements its user-level I/O stack, Extaris, which interfaces directly with virtual function device drivers, allowing for zero-copy I/O and efficient network packet handling. This optimizes for both latency and throughput by avoiding synchronization points or serialization of packet operations [1], [5].\n",
            "\n",
            "4. **Asynchronous Notification Mechanisms**: The use of hardware virtualized interrupts, or doorbells, allows applications to receive notifications directly from hardware to user programs. This mechanism provides lightweight notifications for I/O completions and high-priority packet receptions, thus minimizing latency and overhead [5].\n",
            "\n",
            "These features increase hardware complexity as they require advanced virtualization capabilities and sophisticated management interfaces. However, they can also potentially raise hardware costs due to the need for more sophisticated designs and components that facilitate these functions. Despite this, they significantly enhance system performance by eliminating unnecessary kernel mediation, thereby providing fast, customized device access directly to applications [2], [5].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: Arrakis.pdf\n",
            "    Path: s3://rag-vector-db-poc/Arrakis.pdf\n",
            "    Department: root\n",
            "    Text: By\n",
            "issuing appropriate cache Ô¨Çush commands to the...\n",
            "\n",
            "[2] File: Arrakis.pdf\n",
            "    Path: s3://rag-vector-db-poc/Arrakis.pdf\n",
            "    Department: root\n",
            "    Text: ‚Ä¢Appropriate OS/hardware abstractions: Arrakis‚Äô ab...\n",
            "\n",
            "[3] File: Arrakis.pdf\n",
            "    Path: s3://rag-vector-db-poc/Arrakis.pdf\n",
            "    Department: root\n",
            "    Text: To mea-\n",
            "sure the expected VSIC performance with di...\n",
            "\n",
            "[4] File: Arrakis.pdf\n",
            "    Path: s3://rag-vector-db-poc/Arrakis.pdf\n",
            "    Department: root\n",
            "    Text: Nemesis [ 15] reduces\n",
            "shared components to provide...\n",
            "\n",
            "[5] File: Arrakis.pdf\n",
            "    Path: s3://rag-vector-db-poc/Arrakis.pdf\n",
            "    Department: root\n",
            "    Text: 3.6 Network Data Plane Interface\n",
            "In Arrakis, appli...\n",
            "\n",
            "->>Latency: 3005.05 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 3: In what ways can the Arrakis architecture be extended or adapted to virtualized environments and multi-tenant cloud data centers, and what challenges might arise in such contexts? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "The Arrakis architecture can be extended to virtualized environments, primarily by moving the control plane into the virtual machine monitor (VMM), which allows guest applications to allocate virtual interface cards directly from the VMM. This can be accomplished by pre-allocating a set number of virtual interface cards in the VMM to the guest and letting applications choose only from this predetermined set. This approach does not require a special interface to the VMM and maintains the hardware limits on virtual adapters present in a standard Arrakis environment [5].\n",
            "\n",
            "When considering adaptation to multi-tenant cloud data centers, challenges might arise in ensuring isolation and performance consistency across different tenants. The transition from kernel to user-level operations in Arrakis could introduce complexities in maintaining tenant separation and control, similar to those faced in container-based cloud environments. Utilizing hypervisor-based virtualization, as seen in projects like Kata Containers, could offer solutions for improved isolation, but might also introduce overhead and sacrifice some performance benefits that Arrakis offers with direct device access [3]. \n",
            "\n",
            "Additionally, implementing Arrakis' architecture in multi-tenant environments might require careful management of resource allocation and performance isolation, especially if operating system kernels are bypassed for user-level application execution. While user-level applications can provide improved network performance and QoS enforcement, such as rate limiting, maintaining the protection and policing benefits in a shared, multi-tenant environment could be challenging [5].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: Arrakis.pdf\n",
            "    Path: s3://rag-vector-db-poc/Arrakis.pdf\n",
            "    Department: root\n",
            "    Text: ‚Ä¢Appropriate OS/hardware abstractions: Arrakis‚Äô ab...\n",
            "\n",
            "[2] File: Arrakis.pdf\n",
            "    Path: s3://rag-vector-db-poc/Arrakis.pdf\n",
            "    Department: root\n",
            "    Text: By\n",
            "issuing appropriate cache Ô¨Çush commands to the...\n",
            "\n",
            "[3] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: Workloads must be isolated both for security (so o...\n",
            "\n",
            "[4] File: Arrakis.pdf\n",
            "    Path: s3://rag-vector-db-poc/Arrakis.pdf\n",
            "    Department: root\n",
            "    Text: Nemesis [ 15] reduces\n",
            "shared components to provide...\n",
            "\n",
            "[5] File: Arrakis.pdf\n",
            "    Path: s3://rag-vector-db-poc/Arrakis.pdf\n",
            "    Department: root\n",
            "    Text: On Linux, we\n",
            "use queuing disciplines [ 29] (speciÔ¨Å...\n",
            "\n",
            "->>Latency: 2322.15 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 4: How does OptFS's approach to decoupling ordering and durability via osync() and dsync() primitives impact overall system performance and reliability? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "OptFS's approach to decoupling ordering and durability through the introduction of `osync()` and `dsync()` primitives significantly impacts system performance and reliability by enabling application-level consistency at high performance. Specifically, OptFS allows applications to order writes without incurring a disk flush, thus providing eventual durability and improving system efficiency. The `osync()` primitive ensures the ordering of writes but promises only eventual durability, which helps in building higher-level application consistency semantics without the heavy performance costs associated with immediate durability. On the other hand, `dsync()` ensures immediate durability along with ordering, allowing applications that require synchronous durability to request it.\n",
            "\n",
            "This separation of write-ordering from durability boosts performance for many workloads. OptFS delivers performance similar to ext4 without flushes, being roughly 40x faster per operation than ext4 with flushes [3]. By allowing eventual durability, OptFS avoids the prohibitively expensive cache flushes that traditional systems use to ensure write ordering, which can lead to inefficiencies and long latencies for disk reads due to waiting for pending writes to complete [5]. By adopting an optimistic crash consistency model, OptFS recovers correctly from crashes and provides meaningful semantics for higher-level application design, while still meeting durability demands when necessary [4].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: OntheCreateÔ¨Ålesbenchmark,OptFSperforms2xbet-\n",
            "ter t...\n",
            "\n",
            "[2] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: In that work, the authors clev-\n",
            "erly note that dis...\n",
            "\n",
            "[3] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: OptFS delivers per-\n",
            "formance similar to ext4 witho...\n",
            "\n",
            "[4] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: OptimisticCrash Consistency\n",
            "V\n",
            "ijay Chidambaram, Th...\n",
            "\n",
            "[5] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: By allow-\n",
            "ing applications to order writes without...\n",
            "\n",
            "->>Latency: 2062.49 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 5: In what ways does optimistic crash consistency differ from traditional journaling or soft updates methods, and what are its primary advantages and potential drawbacks? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "Optimistic crash consistency differs from traditional journaling and soft updates methods primarily in how it handles the ordering and durability of writes. Traditional journaling systems, such as those in Linux ext3, XFS, and NTFS, use a sequence of updates to ensure that writes to main file system structures and the journal are completed in a specific order, typically guaranteed by cache flush operations, which are expensive [2]. Soft updates use flushes to ensure ordering but are not flush-free, as they can't force writes to disk, leading to eventual durability [3].\n",
            "\n",
            "In contrast, optimistic crash consistency decouples the ordering of writes from their durability. It allows for higher performance by using techniques like asynchronous durability notifications and avoiding unnecessary cache flushes [2], [4]. This approach allows writes to be reordered by the disk to optimize performance, assuming there isn't a crash. If a crash does occur, the recovery process ensures consistency by preserving the desired properties of transactions [5].\n",
            "\n",
            "The primary advantages of optimistic crash consistency include improved performance, particularly for workloads with many ordering points, because it reduces the need for expensive flush operations. It also provides a mechanism for achieving immediate durability when needed, through the use of file-system primitives like osync() and dsync() [3]. These primitives allow applications to specify whether ordering or durability is needed for specific operations, thus optimizing performance without sacrificing correctness [3].\n",
            "\n",
            "However, the potential drawbacks of optimistic crash consistency include its reliance on the assumption that crashes are relatively rare and that the disk has sufficient mechanisms to notify the file system when data has been made durable. This could imply that in a scenario with frequent crashes, the optimistic approach might not maintain the same level of consistency as traditional methods. Also, because it allows writes to be reordered in some cases, ensuring that all applications' consistency requirements are met might be more complex [5].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: 4.3 Optimistic Techniques\n",
            "The behavior of optimist...\n",
            "\n",
            "[2] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: OptimisticCrash Consistency\n",
            "V\n",
            "ijay Chidambaram, Th...\n",
            "\n",
            "[3] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: We have discussed some of them, such as\n",
            "SoftUpdate...\n",
            "\n",
            "[4] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: SpeciÔ¨Åcally, D:2\n",
            "andM:2 have been checkpointed, bu...\n",
            "\n",
            "[5] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: We show\n",
            "thatthesepropertiescanbeachievedusingacomb...\n",
            "\n",
            "->>Latency: 4040.42 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 6: How do the case studies with gedit and SQLite demonstrate the practical benefits and limitations of the proposed optimistic crash consistency techniques? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "The case studies with gedit and SQLite demonstrate both the practical benefits and limitations of the proposed optimistic crash consistency techniques implemented in OptFS.\n",
            "\n",
            "**Benefits:**\n",
            "\n",
            "1. **Performance Improvement**: The use of OptFS, which employs optimistic crash consistency techniques, significantly improves performance. For gedit, replacing fsync() with osync() ensures order is preserved without the overhead of ensuring immediate durability. The atomic updates become more efficient, with OptFS performing faster than ext4 with flushes [4].\n",
            "   \n",
            "2. **Consistency Assurance**: The case studies show that OptFS consistently results in the database or data files being in either the old or new state after a crash, thereby achieving atomicity. In SQLite, transactions are consistently recovered to either pre- or post-transaction states [3].\n",
            "\n",
            "3. **Flush-Free Operation**: By decoupling ordering and durability, OptFS can maintain high consistency and performance without frequent cache flush operations, making it suitable for applications that may not need immediate durability, as exemplified by the tasks in SQLite [2].\n",
            "\n",
            "**Limitations:**\n",
            "\n",
            "1. **Delayed Durability**: OptFS makes a trade-off between immediate durability and performance. By delaying writes until necessary, there is a risk that recent changes are not immediately persisted, which might not be suitable for applications requiring immediate data durability after each transaction [4].\n",
            "\n",
            "2. **Dependent on Order Guarantees**: OptFS relies on the order of writes being maintained. While it handles ordering effectively through osync(), the reliance on such ordering without real-time flushing means that any lapse or misconfiguration could potentially lead to inconsistencies [4].\n",
            "\n",
            "Overall, these case studies underline the advantage of adopting an optimistic crash consistency approach where performance is prioritized, and slight delays in durability are acceptable [3], [4].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: OptimisticCrash Consistency\n",
            "V\n",
            "ijay Chidambaram, Th...\n",
            "\n",
            "[2] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: We have discussed some of them, such as\n",
            "SoftUpdate...\n",
            "\n",
            "[3] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: OptFS delivers per-\n",
            "formance similar to ext4 witho...\n",
            "\n",
            "[4] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: Moreover, OptFS delays data writes until trans-\n",
            "ac...\n",
            "\n",
            "[5] File: the_linux_schedule_a_decade_of_wasted_cores.pdf\n",
            "    Path: s3://rag-vector-db-poc/the_linux_schedule_a_decade_of_wasted_cores.pdf\n",
            "    Department: root\n",
            "    Text: Using Crash Hoare logic for certifying the\n",
            "FSCQ Ô¨Ål...\n",
            "\n",
            "->>Latency: 4593.57 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 7: How does Demikernel achieve nanosecond-scale I/O processing overheads while maintaining portability across heterogeneous kernel-bypass devices? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "Demikernel achieves nanosecond-scale I/O processing overheads and maintains portability across heterogeneous kernel-bypass devices through several design strategies. Firstly, Demikernel uses a portable datapath API and flexible OS architecture that accommodates diverse kernel-bypass devices with interchangeable library OSes, allowing it to seamlessly integrate with RDMA, DPDK, SPDK, and potential future hardware [5]. Each library OS supports a specific kernel-bypass device and includes an I/O processing stack, a specialized memory allocator, and a centralized coroutine scheduler [3]. This architecture allows for efficient I/O processing by leveraging Rust‚Äôs language features for memory safety and asynchronous programming, contributing to low-latency handling of I/O operations [3].\n",
            "\n",
            "Demikernel also extends POSIX with the portable datapath interface (PDPIX) specifically designed for Œºs-scale kernel-bypass I/O. PDPIX centers around an I/O queue abstraction, which allows applications to submit complete I/O requests, reducing latency compared to traditional POSIX I/O abstractions [5]. By using a queue-oriented approach, Demikernel enhances the ability to perform fast, non-blocking I/O operations, further minimizing processing overheads [4].\n",
            "\n",
            "Furthermore, Demikernel implements zero-copy I/O to eliminate unnecessary data copying, which is critical for reducing latency. It achieves this by coordinating zero-copy memory access carefully across the I/O device, stack, and application, although this requires additional memory management coordination from users [2].\n",
            "\n",
            "Overall, Demikernel's design is driven by the need to balance high-performance with flexibility in supporting various kernel-bypass OS offloads, facilitating ns-scale processing while maintaining compatibility across heterogeneous systems [1][2][5].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: Demikernel.pdf\n",
            "    Path: s3://rag-vector-db-poc/Demikernel.pdf\n",
            "    Department: root\n",
            "    Text: If\n",
            "the application modified or freed the memory bu...\n",
            "\n",
            "[2] File: Demikernel.pdf\n",
            "    Path: s3://rag-vector-db-poc/Demikernel.pdf\n",
            "    Department: root\n",
            "    Text: This section\n",
            "details the requirements of ¬µs-scale...\n",
            "\n",
            "[3] File: Demikernel.pdf\n",
            "    Path: s3://rag-vector-db-poc/Demikernel.pdf\n",
            "    Department: root\n",
            "    Text: 5 Demikernel Datapath Library OS Design\n",
            "Figure 3 s...\n",
            "\n",
            "[4] File: Demikernel.pdf\n",
            "    Path: s3://rag-vector-db-poc/Demikernel.pdf\n",
            "    Department: root\n",
            "    Text: Finally, Demikernel gives (M3) use-after-free\n",
            "prot...\n",
            "\n",
            "[5] File: Demikernel.pdf\n",
            "    Path: s3://rag-vector-db-poc/Demikernel.pdf\n",
            "    Department: root\n",
            "    Text: Demikernel\n",
            "datapath OSes have a per-I/O budget of...\n",
            "\n",
            "->>Latency: 3331.87 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 8: In what ways does the PDPIX API improve programmability for ¬µs-scale datacenter systems compared to traditional POSIX or existing kernel-bypass APIs? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "The PDPIX API improves programmability for ¬µs-scale datacenter systems in several ways compared to traditional POSIX or existing kernel-bypass APIs:\n",
            "\n",
            "1. **Minimal Application Changes**: PDPIX is designed to minimize the changes needed for existing ¬µs-scale applications. It achieves this by limiting the modifications to POSIX to aspects that reduce overheads or better support kernel-bypass I/O. This means applications can leverage PDPIX with fewer adjustments, maintaining compatibility with existing designs while benefiting from enhanced performance [1].\n",
            "\n",
            "2. **Queue-oriented Design**: Instead of the traditional file-oriented design of POSIX, PDPIX uses a queue-oriented approach. For instance, operations that traditionally return a file descriptor now return a queue descriptor. This reflects a shift towards a model that more closely aligns with the actual operations in a kernel-bypass environment, thereby simplifying the way applications handle I/O operations [1].\n",
            "\n",
            "3. **Non-blocking Operations**: The push and pop operations in PDPIX are non-blocking and return a qtoken indicating their asynchronous result. This allows applications to perform other tasks while waiting for the completion of I/O operations, enhancing the efficiency of resource utilization in ¬µs-scale systems. This contrasts with blocking I/O operations typically seen in POSIX, providing more flexibility for high-performance requirements [1].\n",
            "\n",
            "4. **Zero-Copy I/O**: PDPIX supports zero-copy I/O with clear semantics, which is crucial for reducing latency. This involves tightly coordinating memory access between the OS and application, thus minimizing the overhead common in traditional systems where I/O operations may involve multiple data copying stages [2], [3].\n",
            "\n",
            "5. **DMA-capable Memory**: PDPIX ensures that all I/O operations are performed from the DMA-capable heap, facilitating efficient direct memory access which is vital for zero-copy I/O. The responsibility of managing memory pointers and freeing them is given back to the application, thus simplifying the management of memory resources for applications [1].\n",
            "\n",
            "By offering these features, PDPIX facilitates the implementation of efficient kernel-bypass I/O necessary for ¬µs-scale datacenter systems without requiring extensive re-architecting of applications as traditional POSIX or older kernel-bypass APIs might [1], [2].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: Demikernel.pdf\n",
            "    Path: s3://rag-vector-db-poc/Demikernel.pdf\n",
            "    Department: root\n",
            "    Text: Finally, Demikernel gives (M3) use-after-free\n",
            "prot...\n",
            "\n",
            "[2] File: Demikernel.pdf\n",
            "    Path: s3://rag-vector-db-poc/Demikernel.pdf\n",
            "    Department: root\n",
            "    Text: Without a standard datapath architecture and gener...\n",
            "\n",
            "[3] File: Demikernel.pdf\n",
            "    Path: s3://rag-vector-db-poc/Demikernel.pdf\n",
            "    Department: root\n",
            "    Text: This section\n",
            "details the requirements of ¬µs-scale...\n",
            "\n",
            "[4] File: Demikernel.pdf\n",
            "    Path: s3://rag-vector-db-poc/Demikernel.pdf\n",
            "    Department: root\n",
            "    Text: The Demikernel Datapath OS Architecture for\n",
            "Micros...\n",
            "\n",
            "[5] File: Demikernel.pdf\n",
            "    Path: s3://rag-vector-db-poc/Demikernel.pdf\n",
            "    Department: root\n",
            "    Text: Likewise, software middleboxes have\n",
            "used DPDK for...\n",
            "\n",
            "->>Latency: 4523.48 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 9: What challenges did the authors face when integrating networking (e.g., DPDK, RDMA) and storage (e.g., SPDK) libOSes in a single Demikernel datapath OS, and how were they addressed? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "The authors faced challenges in integrating network and storage libOSes because not all kernel-bypass devices work well together. For instance, while DPDK and SPDK can cooperate, RDMA and SPDK were not designed to interact seamlessly. Specifically, SPDK shares the DPDK memory allocator, which leads to the automatic initialization of a DPDK instance. This creates a conflict for RDMA integration because the DPDK instance can occupy the NIC, making it inaccessible for RDMA. Therefore, the authors addressed this issue by carefully blocklisting all NICs for DPDK to allow RDMA functionality [2].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: Demikernel.pdf\n",
            "    Path: s3://rag-vector-db-poc/Demikernel.pdf\n",
            "    Department: root\n",
            "    Text: 5 Demikernel Datapath Library OS Design\n",
            "Figure 3 s...\n",
            "\n",
            "[2] File: Demikernel.pdf\n",
            "    Path: s3://rag-vector-db-poc/Demikernel.pdf\n",
            "    Department: root\n",
            "    Text: To support network and storage devices together, D...\n",
            "\n",
            "[3] File: Demikernel.pdf\n",
            "    Path: s3://rag-vector-db-poc/Demikernel.pdf\n",
            "    Department: root\n",
            "    Text: To minimize latency, Demikernel libOSes offload OS...\n",
            "\n",
            "[4] File: Demikernel.pdf\n",
            "    Path: s3://rag-vector-db-poc/Demikernel.pdf\n",
            "    Department: root\n",
            "    Text: This section\n",
            "details the requirements of ¬µs-scale...\n",
            "\n",
            "[5] File: Demikernel.pdf\n",
            "    Path: s3://rag-vector-db-poc/Demikernel.pdf\n",
            "    Department: root\n",
            "    Text: Finally, Demikernel gives (M3) use-after-free\n",
            "prot...\n",
            "\n",
            "->>Latency: 1406.93 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 10: How does Pond balance the trade-off between latency sensitivity and DRAM savings when determining VM memory allocation, and what role do its machine learning models play in this process? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "Pond balances the trade-off between latency sensitivity and DRAM savings by utilizing machine learning models to predict workload insensitivity to latency and the amount of untouched memory. These models help Pond decide whether a virtual machine (VM) can use pool DRAM without significant performance degradation, thereby optimizing DRAM savings. The latency insensitivity model enables Pond to identify workloads that can tolerate memory latency increases, while the untouched-memory model predicts the portion of a VM's memory that remains unused and can therefore be allocated on the memory pool without impacting performance [4], [5].\n",
            "\n",
            "Pond's machine learning models are designed to minimize false positives in prediction, ensuring that sensitive workloads are not improperly allocated to the pool DRAM [4]. For example, under scenarios of increased memory latency, Pond might label some workloads as insensitive to latency, thus allowing those to use pool memory and save local DRAM for latency-sensitive workloads [3]. The models use telemetry data available for all VM types, enabling Pond to dynamically adjust memory allocations based on real-time usage and performance monitoring [4]. \n",
            "\n",
            "This approach, including the use of a performance degradation margin (PDM) and tail-percentage (TP) parameters, allows Pond to safely reduce overall DRAM requirements while maintaining performance targets [5].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: Pond.pdf\n",
            "    Path: s3://rag-vector-db-poc/Pond.pdf\n",
            "    Department: root\n",
            "    Text: Second, by emulating either 64ns or 140ns of addit...\n",
            "\n",
            "[2] File: Pond.pdf\n",
            "    Path: s3://rag-vector-db-poc/Pond.pdf\n",
            "    Department: root\n",
            "    Text: From this analysis, we draw a few\n",
            "important observ...\n",
            "\n",
            "[3] File: Pond.pdf\n",
            "    Path: s3://rag-vector-db-poc/Pond.pdf\n",
            "    Department: root\n",
            "    Text: Under a 222% increase in memory latency, we find t...\n",
            "\n",
            "[4] File: Pond.pdf\n",
            "    Path: s3://rag-vector-db-poc/Pond.pdf\n",
            "    Department: root\n",
            "    Text: Hypervisor\n",
            "access bitsCore\n",
            "PMUCPUWorkload history?...\n",
            "\n",
            "[5] File: Pond.pdf\n",
            "    Path: s3://rag-vector-db-poc/Pond.pdf\n",
            "    Department: root\n",
            "    Text: 6.5 End-to-End Reduction in Stranding\n",
            "We character...\n",
            "\n",
            "->>Latency: 2166.79 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 11: Given the increasing access latency with larger CXL memory pool sizes, what are the practical scalability limits of Pond's architecture, and how do these limits impact overall datacenter design? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "Pond's architecture is designed to effectively balance memory latency and scalability by limiting the CXL memory pool sizes primarily to 8-16 sockets, as this configuration is enough to achieve most of the benefits while maintaining low access latency [3]. The aim is to keep latency increase minimal, as excessive latency could lead to significant performance slowdowns, especially in latency-sensitive workloads [4].\n",
            "\n",
            "The practical scalability limits are influenced by the latency introduced by CXL components like retimers and switches. Retimers add approximately 10ns of latency each way, and switches add at least 70ns due to ports, arbitration, and network on chip (NOC) [1]. With these latencies in mind, Pond reduces access latencies by about one-third compared to designs that rely only on switches [1]. Consequently, Pond's architecture is focused on reducing latency and avoiding fragmentation, which is vital in a cloud environment where minimizing latency-related slowdowns is crucial.\n",
            "\n",
            "This design choice impacts datacenter design by encouraging the use of smaller, more efficient CXL pools, which use fewer resources and have lower cost overheads. This approach offers performance that is within 1-5% of same-NUMA-node VM allocations, making it a practical solution for managing memory resources at scale in large cloud providers, with reduced DRAM needs by 7% in a 16-socket pool configuration [2], [4].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: Pond.pdf\n",
            "    Path: s3://rag-vector-db-poc/Pond.pdf\n",
            "    Department: root\n",
            "    Text: The optimal design point balances the potential po...\n",
            "\n",
            "[2] File: Pond.pdf\n",
            "    Path: s3://rag-vector-db-poc/Pond.pdf\n",
            "    Department: root\n",
            "    Text: An\n",
            "open-source version of Pond‚Äôs emulation layer a...\n",
            "\n",
            "[3] File: Pond.pdf\n",
            "    Path: s3://rag-vector-db-poc/Pond.pdf\n",
            "    Department: root\n",
            "    Text: Pond: CXL-Based Memory Pooling Systems for Cloud P...\n",
            "\n",
            "[4] File: Pond.pdf\n",
            "    Path: s3://rag-vector-db-poc/Pond.pdf\n",
            "    Department: root\n",
            "    Text: Under a 222% increase in memory latency, we find t...\n",
            "\n",
            "[5] File: Pond.pdf\n",
            "    Path: s3://rag-vector-db-poc/Pond.pdf\n",
            "    Department: root\n",
            "    Text: Pond must avoid fragmenting its online pool memory...\n",
            "\n",
            "->>Latency: 3433.5 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 12: How does Pond‚Äôs zNUMA approach differ from traditional NUMA memory management, and what mechanisms ensure performance remains consistent even with incorrect memory usage predictions? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "Pond's zNUMA approach differs from traditional NUMA memory management by integrating a memory pool system that leverages CXL technology to allocate memory on a zero-core virtual NUMA (zNUMA) node. The primary distinct feature of zNUMA is that it allows the allocation of untouched memory from a shared pool across multiple VMs, minimizing performance impacts. Unlike typical NUMA nodes, zNUMA nodes do not have associated CPUs, resembling Linux's CPU-less NUMA concept [3].\n",
            "\n",
            "The mechanism that ensures performance consistency even with incorrect memory usage predictions involves a substantial focus on predicting latency sensitivity and untouched memory usage. Pond employs machine learning models to predict whether a VM will be latency-sensitive and the amount of untouched memory. In instances of incorrect predictions, Pond introduces a monitoring system that detects poor memory performance and triggers a migration to use only same-NUMA-node memory. This proactive measure mitigates performance impacts by ensuring that latency-sensitive VMs are allocated on the memory with optimal performance [3], [4]. Additionally, the system uses a RandomForest model to forecast the workloads' sensitivity to DRAM boundedness, offering a robust prediction framework better than simple DRAM or memory bound heuristics [2].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: Pond.pdf\n",
            "    Path: s3://rag-vector-db-poc/Pond.pdf\n",
            "    Department: root\n",
            "    Text: The model uses a set of 200 hardware counters as s...\n",
            "\n",
            "[2] File: Pond.pdf\n",
            "    Path: s3://rag-vector-db-poc/Pond.pdf\n",
            "    Department: root\n",
            "    Text: We rerun each workload on all-local memory, a corr...\n",
            "\n",
            "[3] File: Pond.pdf\n",
            "    Path: s3://rag-vector-db-poc/Pond.pdf\n",
            "    Department: root\n",
            "    Text: Second, by emulating either 64ns or 140ns of addit...\n",
            "\n",
            "[4] File: Pond.pdf\n",
            "    Path: s3://rag-vector-db-poc/Pond.pdf\n",
            "    Department: root\n",
            "    Text: An\n",
            "open-source version of Pond‚Äôs emulation layer a...\n",
            "\n",
            "[5] File: Pond.pdf\n",
            "    Path: s3://rag-vector-db-poc/Pond.pdf\n",
            "    Department: root\n",
            "    Text: From this analysis, we draw a few\n",
            "important observ...\n",
            "\n",
            "->>Latency: 2323.41 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 13: How does HeMem's asynchronous sampling via PEBS compare in scalability and accuracy to traditional page table scanning for hot data identification, especially as memory capacity reaches terabyte scale? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "HeMem's asynchronous sampling via PEBS exhibits better scalability and accuracy compared to traditional page table scanning, especially as memory capacity increases to terabyte scale. The PEBS method minimizes interference from other long-running tasks by using a separate PEBS thread to continuously read buffers and update page statistics, effectively distinguishing between hot and cold data without being delayed by migrations [3]. By sampling memory accesses and monitoring the virtual addresses of sampled instructions, HeMem can track memory access at a granular level more efficiently than page table scanning approaches, which are constrained by hardware page sizes and suffer from long scanning times [3].\n",
            "\n",
            "In contrast, page table scanning is shown to have high overheads, particularly for large memory sizes. For example, in a 512 GB working set scenario, synchronous page table scanning achieves only 18% throughput compared to optimal methods due to delays in migrations and overestimation of the hot set. Even asynchronous page table scanning only reaches 43% of the optimal throughput, as it overestimates hot data, considering up to 300 GB as hot, leading to unnecessary NVM accesses and migrations [1]. As a result, HeMem's asynchronous PEBS sampling is significantly more efficient and scalable than traditional page table scanning methods, particularly for handling large memory capacities effectively [1][3].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: 0 0.02 0.04 0.06 0.08 0.1 0.12\n",
            " 0  50  100  150  2...\n",
            "\n",
            "[2] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: Once the hot set\n",
            "shifts, there is a noticeable dro...\n",
            "\n",
            "[3] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: We find that a sample period of approx-\n",
            "imately 5,...\n",
            "\n",
            "[4] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: Next, we fix the sampling period at 5k and vary th...\n",
            "\n",
            "[5] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: To avoid having to traverse the FIFO queues\n",
            "of all...\n",
            "\n",
            "->>Latency: 2296.71 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 14: Given HeMem‚Äôs user-space implementation and its reliance on userfaultfd and DMA migration, what are the potential challenges or limitations in extending it to support kernel-level memory or shared memory scenarios in multi-tenant cloud environments? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "HeMem's user-space implementation and its reliance on userfaultfd and DMA migration present several potential challenges or limitations if it were to be extended to support kernel-level memory or shared memory in multi-tenant cloud environments.\n",
            "\n",
            "1. **Userfaultfd Limitations**: HeMem's use of userfaultfd for handling page faults and write-protection is currently a user-space feature and heavily relies on patches that are not yet integrated into the mainline Linux kernel [1]. Extending this mechanism to kernel-level or shared memory could require significant changes to the kernel itself, which may not be feasible in shared environments where the kernel is shared among multiple tenants.\n",
            "\n",
            "2. **Security and Isolation**: In multi-tenant environments, security and isolation are critical. While HeMem manages memory allocations and migrations effectively in user-space, ensuring that these operations do not compromise the isolation between tenants when handling shared or global memory mappings can pose a challenge [1]. The cooperative synchronization method mentioned for shared tiered memory might not be sufficient in a multi-tenant scenario where processes do not necessarily trust each other [1].\n",
            "\n",
            "3. **Resource Management**: HeMem's approach to resource management, especially with DMA engines, might face scalability challenges in cloud environments. There is a need for efficient multiplexing of DMA resources across multiple tenants without degrading performance [5]. Implementing such mechanisms at the kernel level would involve complex modifications to manage resources securely and fairly across tenants.\n",
            "\n",
            "4. **Compatibility with Existing Kernel Features**: Integrating HeMem's functionalities with existing kernel memory management features could lead to compatibility issues. Current systems like HeMem are designed to operate alongside or independently of the kernel's memory management, but enabling kernel-level integration could require significant modifications to the Linux kernel's existing memory subsystems [1], [5].\n",
            "\n",
            "5. **Shared Memory Scalability**: The scalability of shared memory management using HeMem's techniques could be a bottleneck, especially when dealing with high numbers of tenants or large-scale cloud deployments. The need to maintain consistent memory mappings and handle them across various virtualized instances can lead to increased complexity and potential performance overheads [1].\n",
            "\n",
            "Overall, extending HeMem to support kernel-level memory or shared memory scenarios in cloud environments would necessitate addressing these technical challenges, particularly in terms of security, isolation, and efficient resource management.\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: One possibility is via the NUMA memory sub-\n",
            "system...\n",
            "\n",
            "[2] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: It allows\n",
            "programmers and application-specific mem...\n",
            "\n",
            "[3] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: We then\n",
            "evaluate how HeMem affects application-lev...\n",
            "\n",
            "[4] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: To avoid having to traverse the FIFO queues\n",
            "of all...\n",
            "\n",
            "[5] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: This\n",
            "is the configuration we use. If a DMA engine...\n",
            "\n",
            "->>Latency: 4815.0 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 15: Considering that HeMem achieves significant reductions in NVM wear, what design principles can be abstracted and applied to emerging memory technologies (e.g., MRAM, ReRAM) with similar asymmetries in read/write performance or endurance? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "HeMem's design principles that significantly reduce NVM wear can indeed be applied to other emerging memory technologies like MRAM and ReRAM, which may have similar asymmetries in read/write performance or endurance. Here are some key principles that can be abstracted:\n",
            "\n",
            "1. **Priority Migration of Write-Heavy Pages:** HeMem prioritizes the migration of write-heavy pages to DRAM over read-heavy pages because NVM performs better with reads than writes and has lower endurance with write operations. Implementing a similar priority-based migration policy can be beneficial for memory technologies with notable differences in read/write endurance [2].\n",
            "\n",
            "2. **Efficiency in Identifying Hot Sets:** HeMem efficiently identifies hot sets through the use of PEBS scanning, which allows for quick recognition of frequently written data. This method minimizes the number of writes to NVM by quickly moving write-heavy data to DRAM. A similar approach could be applied to identify frequently accessed data in emerging memory technologies, thus optimizing their lifespan [2].\n",
            "\n",
            "3. **Reducing Migration Overhead:** HeMem strategically reduces migration overhead by utilizing asynchronous operations when necessary and stops unnecessary migrations when the hot set is too large for DRAM. This smart management of resources helps in maintaining performance while reducing wear. For emerging technologies, minimizing the overhead associated with migration can be crucial as it reduces performance bottlenecks and extends device life [5].\n",
            "\n",
            "4. **Selective Use of Fast Memory for Small/Ephemeral Objects:** HeMem leaves small and ephemeral kernel objects in fast memory. This ensures that resources are not wasted on migrating transient data that does not benefit from being in tiered memory. For technologies with limited endurance, keeping such objects in more durable memory could be beneficial [2].\n",
            "\n",
            "By applying these principles, emerging memory technologies with varying endurance and performance characteristics can potentially improve their efficiency and lifespan significantly.\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: Nimble‚Äôs sequential scanning and migration\n",
            "approac...\n",
            "\n",
            "[2] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: HeMem‚Äôs migration policy scans the\n",
            "DRAM cold list...\n",
            "\n",
            "[3] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: We then\n",
            "evaluate how HeMem affects application-lev...\n",
            "\n",
            "[4] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: Once the hot set\n",
            "shifts, there is a noticeable dro...\n",
            "\n",
            "[5] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: We now make a random set of each thread‚Äôs ob-\n",
            "ject...\n",
            "\n",
            "->>Latency: 3829.47 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 16: What architectural and implementation choices enabled Firecracker to achieve both low overhead and strong isolation compared to traditional hypervisors like QEMU? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "Firecracker achieves low overhead and strong isolation through several architectural and implementation choices:\n",
            "\n",
            "1. **Minimal VMM Design**: Firecracker replaces the traditional Virtual Machine Monitor (VMM) with a minimal implementation written in Rust, which reduces the codebase to approximately 50k lines, significantly fewer than QEMU. This minimalism reduces the surface area and improves the security of the system [2].\n",
            "\n",
            "2. **Use of KVM**: By leveraging the Linux Kernel's KVM virtualization infrastructure, Firecracker can provide efficient virtualization with strong isolation. This approach allows Firecracker to focus on providing minimal virtual machines (MicroVMs) and offload more complex operations to the existing Linux components [2].\n",
            "\n",
            "3. **Process-per-VM Model**: Each Firecracker instance runs as a separate process, providing a simple isolation model. This separation ensures that even if one MicroVM is compromised, others remain unaffected, thereby enhancing security isolation [2].\n",
            "\n",
            "4. **Optimized Boot Time**: Firecracker has been optimized to boot MicroVMs swiftly, with boot times as low as 150ms in production configurations. This fast switching capability is critical for environments like AWS Lambda, where performance and quick scaling are necessary [4].\n",
            "\n",
            "5. **Reliance on Linux Infrastructure**: Firecracker uses high-quality Linux operating system components, such as schedulers and memory managers, to handle complexity and improve performance. This approach saves the overhead of duplicating these complex systems within the VMM itself [2].\n",
            "\n",
            "Together, these design decisions allow Firecracker to maintain a lightweight footprint, reducing both CPU and memory overhead, while ensuring strong isolation for secure operation of multiple tenants on shared hardware [4].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: Pre-conÔ¨Ågured Firecracker and the Cloud Hypervisor...\n",
            "\n",
            "[2] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: The NEMU [24] project aims to cut down QEMU by rem...\n",
            "\n",
            "[3] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: Firecracker has been used\n",
            "in production in Lambda...\n",
            "\n",
            "[4] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: Some improvements, such as exposing parallel\n",
            "disk...\n",
            "\n",
            "[5] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: We use Firecracker\n",
            "v0.20.0 as the base line and us...\n",
            "\n",
            "->>Latency: 3715.76 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 17: How does Firecracker‚Äôs design and integration with AWS Lambda enable fast function startup and efficient resource utilization at massive scale? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "Firecracker's design and integration with AWS Lambda enable fast function startup and efficient resource utilization at massive scale primarily through its architecture, which facilitates quick boot times and the reuse of execution environments, and through optimizations such as sticky routing and load balancing.\n",
            "\n",
            "1. **Fast Function Startup:** Firecracker allows MicroVMs to boot with a production kernel and userland in as little as 150ms. This rapid boot time enables Lambda functions to start quickly, which is critical for handling trillions of events per month efficiently [1].\n",
            "\n",
            "2. **Efficient Resource Utilization:** Within the Lambda architecture, each worker offers slots that provide pre-loaded execution environments for functions. These slots are reused for many serial invocations of the function, which reduces overhead and improves concurrency management. Workers are also managed using a load-balancing protocol that helps distribute resource demands evenly across the infrastructure, minimizing potential bottlenecks and optimizing resource allocation [5].\n",
            "\n",
            "3. **Sticky Routing and Concurrency Control:** The Worker Manager plays a vital role in ensuring efficient execution by sticky-routing events to workers that are already handling requests for specific functions. This technique enhances cache locality and connection reuse while amortizing operational costs. Concurrency control protocols further ensure that multiple invoke services can operate against a shared pool of workers without creating race conditions, which contributes to the efficient processing of a massive number of requests [5].\n",
            "\n",
            "Overall, Firecracker‚Äôs minimalistic and focused design combined with Lambda‚Äôs sophisticated orchestration and resource management mechanisms allow AWS Lambda to serve a large number of customers with high reliability and low latency [3], [4].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: Some improvements, such as exposing parallel\n",
            "disk...\n",
            "\n",
            "[2] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: Firecracker has been used\n",
            "in production in Lambda...\n",
            "\n",
            "[3] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: The seccomp-bpf proÔ¨Åle whitelists 24\n",
            "syscalls, eac...\n",
            "\n",
            "[4] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: For example, our Firecracker\n",
            "Ô¨Çeet has Symmetric Mu...\n",
            "\n",
            "[5] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: The Worker Manager replicates sticky routing infor...\n",
            "\n",
            "->>Latency: 9301.77 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 18: In what ways does Firecracker‚Äôs minimal device model and use of Rust for VMM development contribute to reducing the trusted computing base (TCB) and improving security? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "Firecracker's minimal device model and the use of Rust contribute to reducing the trusted computing base (TCB) and improving security in several ways:\n",
            "\n",
            "1. **Minimal Device Model**: Firecracker offers a limited set of emulated devices, specifically focusing on network and block devices, serial ports, and partial support for the i8042 keyboard controller. This minimalism reduces the complexity and the potential attack surface compared to more comprehensive solutions like QEMU, which supports over 40 emulated devices. By not implementing unnecessary device drivers (such as USB or GPU), Firecracker reduces the TCB as fewer components need to be trusted and maintained [3].\n",
            "\n",
            "2. **Rust for VMM Development**: Firecracker is implemented in Rust, a language known for its memory safety features, which eliminates many common vulnerabilities such as buffer overflows and null pointer dereferences. This choice further minimizes the likelihood of security defects in the VMM compared to languages that do not enforce memory safety by design. As a result, the TCB is smaller and inherently more secure [1].\n",
            "\n",
            "Overall, by restricting the number of emulated devices and employing a safe programming language, Firecracker reduces the complexity and size of the TCB, which enhances its security profile without sacrificing its effectiveness for serverless and container workloads.\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: The NEMU [24] project aims to cut down QEMU by rem...\n",
            "\n",
            "[2] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: We implemented performance limits in Firecracker w...\n",
            "\n",
            "[3] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: Using KVM in Linux, along with the standard Linux...\n",
            "\n",
            "[4] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: Some improvements, such as exposing parallel\n",
            "disk...\n",
            "\n",
            "[5] File: FireCracker.pdf\n",
            "    Path: s3://rag-vector-db-poc/FireCracker.pdf\n",
            "    Department: root\n",
            "    Text: Firecracker has been used\n",
            "in production in Lambda...\n",
            "\n",
            "->>Latency: 3179.63 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 19: What key design strategies did the authors implement to manage physical memory fragmentation and ensure sustained superpage performance under memory pressure? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "The authors implemented a few key design strategies to manage physical memory fragmentation and ensure sustained superpage performance under memory pressure, particularly in the context of tiered memory systems like HeMem:\n",
            "\n",
            "1. **Memory Migration with Spare Bandwidth**: They identified that spare memory bandwidth could be effectively used to migrate data among different memory tiers in the background without impacting application performance. This helps in managing memory efficiently under load by dynamically adjusting the placement of data [1].\n",
            "\n",
            "2. **HeMem's Asynchronous Memory Access Sampling**: To avoid the overhead of traditional methods like tracking page table access and dirty bits (often infeasible at large memory scales), HeMem uses asynchronous memory access sampling to dynamically monitor memory access patterns. This significantly reduces CPU overhead and avoids the intensive operations like frequent data-intensive page table scanning and TLB shootdowns, which can cause fragmentation [3].\n",
            "\n",
            "3. **Hot and Cold Data Classification**: Using PEBS (Precise Event-Based Sampling) to classify pages into hot and cold categories helps in deciding which pages should reside in faster memory (DRAM) or can be downgraded to slower storage (NVM), thereby ensuring more efficient utilization of available memory resources and maintaining performance even under memory pressure [2].\n",
            "\n",
            "These strategies aim to optimize both performance and memory resource allocation by proactively managing memory access patterns and efficiently using system resources like bandwidth and computational overhead.\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: ‚Ä¢Accessing small (‚â§4KB) objects randomly on Optane...\n",
            "\n",
            "[2] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: We find that a sample period of approx-\n",
            "imately 5,...\n",
            "\n",
            "[3] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: Lag in OS support for tiered memory (e.g., Linux h...\n",
            "\n",
            "[4] File: xen_and_the_art_of_virtualization.pdf\n",
            "    Path: s3://rag-vector-db-poc/xen_and_the_art_of_virtualization.pdf\n",
            "    Department: root\n",
            "    Text: To increase the efÔ¨Åciency of virtual block de-\n",
            "vic...\n",
            "\n",
            "[5] File: Pond.pdf\n",
            "    Path: s3://rag-vector-db-poc/Pond.pdf\n",
            "    Department: root\n",
            "    Text: Such OS-based ap-\n",
            "proaches bring significant overh...\n",
            "\n",
            "->>Latency: 3421.27 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 20: How does the reservation-based allocation mechanism proposed in the paper differ from eager promotion or relocation-based superpage management strategies used in other operating systems like HP-UX or IRIX? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "The reservation-based allocation mechanism proposed in the paper differs from eager promotion or relocation-based superpage management strategies, such as those used in HP-UX or IRIX, by proactively reserving a contiguous region of physical memory for potential future use as a superpage. This approach avoids the need to relocate pages later to satisfy contiguity and alignment constraints, which is often necessary in systems using relocation-based strategies when pages are first touched and allocated without pre-reservation [5].\n",
            "\n",
            "In relocation-based strategies, pages may need to be physically copied to form a contiguous superpage, which incurs significant costs that can be hard to recover, especially on busy systems. In contrast, reservation-based allocation tries to reserve a set contiguous memory region from the beginning, potentially avoiding such relocation costs [5].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: FFS_Unix.pdf\n",
            "    Path: s3://rag-vector-db-poc/FFS_Unix.pdf\n",
            "    Department: root\n",
            "    Text: McKusick, W. N. Joy, S. J. Leffier, and R. S. Fabr...\n",
            "\n",
            "[2] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: In Proceedings of the Twenty-First Interna-\n",
            "tional...\n",
            "\n",
            "[3] File: xen_and_the_art_of_virtualization.pdf\n",
            "    Path: s3://rag-vector-db-poc/xen_and_the_art_of_virtualization.pdf\n",
            "    Department: root\n",
            "    Text: To increase the efÔ¨Åciency of virtual block de-\n",
            "vic...\n",
            "\n",
            "[4] File: ghOSt.pdf\n",
            "    Path: s3://rag-vector-db-poc/ghOSt.pdf\n",
            "    Department: root\n",
            "    Text: SPDK [ 81], ReFlex [ 82],\n",
            "FUSE [ 83], and DashFS [...\n",
            "\n",
            "[5] File: navarro.pdf\n",
            "    Path: s3://rag-vector-db-poc/navarro.pdf\n",
            "    Department: root\n",
            "    Text: USENIX Association\n",
            "Proceedings of the\n",
            "5th Symposiu...\n",
            "\n",
            "->>Latency: 1568.75 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 21: What are the primary trade-offs involved in the incremental promotion and speculative demotion of superpages, and how do these impact system performance and memory overhead? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "The primary trade-offs involved in the incremental promotion and speculative demotion of superpages are centered around balancing the benefits of reduced TLB (Translation Lookaside Buffer) misses against increased memory consumption and the complexity of managing superpages.\n",
            "\n",
            "1. **Incremental Promotion**: The process involves promoting a collection of base pages to form a superpage once an aligned extent of memory has been fully populated. Incremental promotion can help reduce TLB misses, as it allows a single TLB entry to cover a larger address space. The trade-off, however, is in increased memory consumption if not all constituent pages of the superpage are actively used. Additionally, promoting even slightly populated regions can unnecessarily inflate the application's memory footprint, leading to potential wastage of memory resources [1].\n",
            "\n",
            "2. **Speculative Demotion**: This process aims to ascertain whether all parts of a superpage are actively being accessed. Demotion occurs when a process is no longer using all portions of a superpage under memory pressure, as demoting sections of a superpage can make unused base pages available for other allocations. The challenge lies in the hardware‚Äôs limitation of maintaining only a single reference bit for an entire superpage, meaning demotion decisions are based on probabilistic speculation rather than precise knowledge of page usage [1]. Speculative demotion allows the system to detect unused base pages, avoiding excessive memory allocation, but risks incorrectly demoting pages still in use, potentially increasing the overhead of page faults and TLB misses.\n",
            "\n",
            "In conclusion, these strategies impact system performance by aiming to optimize TLB usage and manage memory consumption effectively. However, they require careful tuning to avoid the pitfalls of promoting underutilized superpages and managing the limited reference bit information efficiently to prevent unnecessary demotions [1].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: navarro.pdf\n",
            "    Path: s3://rag-vector-db-poc/navarro.pdf\n",
            "    Department: root\n",
            "    Text: Promotion:Onceacertainnumberofbasepages\n",
            "withinapot...\n",
            "\n",
            "[2] File: xen_and_the_art_of_virtualization.pdf\n",
            "    Path: s3://rag-vector-db-poc/xen_and_the_art_of_virtualization.pdf\n",
            "    Department: root\n",
            "    Text: To increase the efÔ¨Åciency of virtual block de-\n",
            "vic...\n",
            "\n",
            "[3] File: HeMem.pdf\n",
            "    Path: s3://rag-vector-db-poc/HeMem.pdf\n",
            "    Department: root\n",
            "    Text: ‚Ä¢Accessing small (‚â§4KB) objects randomly on Optane...\n",
            "\n",
            "[4] File: FFS_Unix.pdf\n",
            "    Path: s3://rag-vector-db-poc/FFS_Unix.pdf\n",
            "    Department: root\n",
            "    Text: McKusick, W. N. Joy, S. J. Leffier, and R. S. Fabr...\n",
            "\n",
            "[5] File: Exokernel.pdf\n",
            "    Path: s3://rag-vector-db-poc/Exokernel.pdf\n",
            "    Department: root\n",
            "    Text: Notethatappe12requires lesstimethanappellsinceappe...\n",
            "\n",
            "->>Latency: 3013.46 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 22: What are the main advantages of using a log-structured file system (LFS) compared to traditional Unix file systems, especially in handling small file workloads? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "The context provided does not specifically discuss log-structured file systems (LFS) or directly compare them to traditional Unix file systems in terms of handling small file workloads. The files referenced in the context focus on the Fast File System (FFS) improvements over the traditional Unix file system to enhance throughput and file access rates, but they do not cover LFS explicitly or small file workloads in a detailed comparative manner.\n",
            "\n",
            "However, in general terms, a log-structured file system is typically designed to optimize write operations and recovery processes, which can be beneficial for workloads with many small files, as it can consolidate writes and reduce seek times. In contrast, the traditional Unix file systems, including FFS, focused on improving throughput by using flexible allocation policies and providing enhancements like larger block sizes and long file names [1], [2], [3]. These improvements aimed to enhance access to large files and optimize disk utilization but were not specifically targeted at the small file workload optimization that is typical of LFS designs.\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: FFS_Unix.pdf\n",
            "    Path: s3://rag-vector-db-poc/FFS_Unix.pdf\n",
            "    Department: root\n",
            "    Text: A Fast File System for UNIX \n",
            "MARSHALL K. MCKUSICK,...\n",
            "\n",
            "[2] File: FFS_Unix.pdf\n",
            "    Path: s3://rag-vector-db-poc/FFS_Unix.pdf\n",
            "    Department: root\n",
            "    Text: If each track contains an odd number of sectors,...\n",
            "\n",
            "[3] File: FFS_Unix.pdf\n",
            "    Path: s3://rag-vector-db-poc/FFS_Unix.pdf\n",
            "    Department: root\n",
            "    Text: Since file systems with different \n",
            "block sizes may...\n",
            "\n",
            "[4] File: Unix.pdf\n",
            "    Path: s3://rag-vector-db-poc/Unix.pdf\n",
            "    Department: root\n",
            "    Text: A program which is used rarely or \n",
            "which does no g...\n",
            "\n",
            "[5] File: FFS_Unix.pdf\n",
            "    Path: s3://rag-vector-db-poc/FFS_Unix.pdf\n",
            "    Department: root\n",
            "    Text: McKusick, W. N. Joy, S. J. Leffler, and R. S. Fabr...\n",
            "\n",
            "->>Latency: 2423.31 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 23: How does Sprite LFS manage free space using segment cleaning, and what is the role of the cost-benefit policy in optimizing write performance? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "Sprite LFS manages free space using a technique called segment cleaning, where the disk is divided into segments, and a cleaner process continuously operates to regenerate empty segments by compressing the live data from heavily fragmented segments. This process ensures that there are large extents of free space available for writing new data efficiently [3].\n",
            "\n",
            "The cost-benefit cleaning policy plays a critical role in optimizing write performance by segregating older, more slowly changing data from younger, rapidly-changing data, and treating them differently during the cleaning process. This policy is based on simulations that demonstrated its effectiveness in maintaining large free areas on the disk for fast writing, thereby improving the log-structured filesystem's overall efficiency [3].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: FFS_Unix.pdf\n",
            "    Path: s3://rag-vector-db-poc/FFS_Unix.pdf\n",
            "    Department: root\n",
            "    Text: McKusick, W. N. Joy, S. J. Leffier, and R. S. Fabr...\n",
            "\n",
            "[2] File: LogFS.pdf\n",
            "    Path: s3://rag-vector-db-poc/LogFS.pdf\n",
            "    Department: root\n",
            "    Text: Aneight-kilobyte blocksizewasusedbySunOS\n",
            "whileSpri...\n",
            "\n",
            "[3] File: LogFS.pdf\n",
            "    Path: s3://rag-vector-db-poc/LogFS.pdf\n",
            "    Department: root\n",
            "    Text: TheDesignandImplementation ofaLog-Structured FileS...\n",
            "\n",
            "[4] File: FFS_Unix.pdf\n",
            "    Path: s3://rag-vector-db-poc/FFS_Unix.pdf\n",
            "    Department: root\n",
            "    Text: This performance improvement gave a strong indicat...\n",
            "\n",
            "[5] File: FFS_Unix.pdf\n",
            "    Path: s3://rag-vector-db-poc/FFS_Unix.pdf\n",
            "    Department: root\n",
            "    Text: Thus, the percentage of waste in an old 1024-byte...\n",
            "\n",
            "->>Latency: 1384.36 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== QUESTION 24: In what ways does the crash recovery mechanism in Sprite LFS leverage the log structure to improve reliability and recovery time, and how does this differ from traditional file system recovery approaches? ==========\n",
            "\n",
            "->> Answer:\n",
            "\n",
            "The crash recovery mechanism in Sprite LFS leverages the log structure to improve both reliability and recovery time by eliminating the need for a full disk scan to restore consistency after a crash. In traditional file systems, crash recovery typically involves scanning the entire disk to ensure the disk's state is consistent, which can be time-consuming and complex [4]. In contrast, a log-structured file system like Sprite LFS only needs to examine the most recent portion of the log during recovery. Since all modifications are written sequentially in a log-like format, recovery can be achieved more quickly and efficiently by focusing only on the end of the log where the most recent changes occur [4].\n",
            "\n",
            "This approach not only speeds up the recovery process but also enhances reliability by consistently maintaining a complete and sequential record of changes, reducing the complexity of tracking partial writes or inconsistent states across the disk. This differs significantly from more traditional methods that rely on maintaining multiple points of fail-safe across the disk, which can lead to longer recovery times and increased chance of inconsistency due to their scattered nature [4].\n",
            "\n",
            "->> Top 5 Retrieved Chunks:\n",
            "\n",
            "[1] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: 4.3 Optimistic Techniques\n",
            "The behavior of optimist...\n",
            "\n",
            "[2] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: OptFS delivers per-\n",
            "formance similar to ext4 witho...\n",
            "\n",
            "[3] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: In short, the classic approach of Ô¨Çushing is pes-...\n",
            "\n",
            "[4] File: LogFS.pdf\n",
            "    Path: s3://rag-vector-db-poc/LogFS.pdf\n",
            "    Department: root\n",
            "    Text: TheDesignandImplementation ofaLog-Structured FileS...\n",
            "\n",
            "[5] File: Crash_Consistency.pdf\n",
            "    Path: s3://rag-vector-db-poc/Crash_Consistency.pdf\n",
            "    Department: root\n",
            "    Text: To give the reader some intuition\n",
            "for why particul...\n",
            "\n",
            "->>Latency: 3087.34 ms\n",
            "\n",
            "==================================================\n",
            "\n",
            "========== SUMMARY ==========\n",
            "\n",
            "Total Queries: 24\n",
            "Average Latency: 3207.28 ms\n",
            "\n",
            "Top Accessed Sources:\n",
            "‚Ä¢ s3://rag-vector-db-poc/HeMem.pdf: 20x\n",
            "‚Ä¢ s3://rag-vector-db-poc/Crash_Consistency.pdf: 18x\n",
            "‚Ä¢ s3://rag-vector-db-poc/FireCracker.pdf: 17x\n",
            "‚Ä¢ s3://rag-vector-db-poc/Pond.pdf: 16x\n",
            "‚Ä¢ s3://rag-vector-db-poc/Demikernel.pdf: 15x\n",
            "‚Ä¢ s3://rag-vector-db-poc/Arrakis.pdf: 13x\n",
            "‚Ä¢ s3://rag-vector-db-poc/FFS_Unix.pdf: 9x\n",
            "‚Ä¢ s3://rag-vector-db-poc/xen_and_the_art_of_virtualization.pdf: 3x\n",
            "‚Ä¢ s3://rag-vector-db-poc/LogFS.pdf: 3x\n",
            "‚Ä¢ s3://rag-vector-db-poc/navarro.pdf: 2x\n",
            "‚Ä¢ s3://rag-vector-db-poc/the_linux_schedule_a_decade_of_wasted_cores.pdf: 1x\n",
            "‚Ä¢ s3://rag-vector-db-poc/ghOSt.pdf: 1x\n",
            "‚Ä¢ s3://rag-vector-db-poc/Exokernel.pdf: 1x\n",
            "‚Ä¢ s3://rag-vector-db-poc/Unix.pdf: 1x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF-exrVJAwVw",
        "outputId": "8eec9dfc-acbf-45c2-8036-c8739c88cbac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import uuid, time\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import Distance, VectorParams, PointStruct, Filter, FieldCondition, MatchValue\n",
        "from openai import AzureOpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# ------------------- CONFIG -------------------\n",
        "QDRANT_HOST = \"54.152.12.154\"\n",
        "QDRANT_PORT = 6333\n",
        "COLLECTION = \"docs_chunks\"\n",
        "EMBED_DIM = 384\n",
        "\n",
        "# Azure OpenAI Config (replace with actual values)\n",
        "AZURE_OPENAI_ENDPOINT = \"https://ironclad-openai-001.openai.azure.com/\"\n",
        "AZURE_OPENAI_API_KEY = \"936856630b764210913d9a8fd6c8212b\"\n",
        "AZURE_DEPLOYMENT_NAME = \"gpt-4o\"\n",
        "\n",
        "# ------------------- LOAD MODELS -------------------\n",
        "@st.cache_resource\n",
        "def load_embedder():\n",
        "    return SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_azure_client():\n",
        "    return AzureOpenAI(\n",
        "        api_key=AZURE_OPENAI_API_KEY,\n",
        "        api_version=\"2023-05-15\",\n",
        "        azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
        "    )\n",
        "\n",
        "embed_model = load_embedder()\n",
        "azure_client = load_azure_client()\n",
        "\n",
        "# ------------------- QDRANT -------------------\n",
        "client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT, timeout=120)\n",
        "\n",
        "# ------------------- MONITORING -------------------\n",
        "monitoring = {\n",
        "    \"access_count\": defaultdict(int),\n",
        "    \"latencies\": [],\n",
        "    \"query_log\": []\n",
        "}\n",
        "\n",
        "# ------------------- RAG -------------------\n",
        "def search_qdrant(query, k=3):\n",
        "    vec = embed_model.encode([query])[0]\n",
        "\n",
        "    results = client.query_points(\n",
        "        collection_name=COLLECTION,\n",
        "        query=vec,\n",
        "        limit=k,\n",
        "        with_payload=True,\n",
        "        timeout=120\n",
        "    )\n",
        "\n",
        "    metadata_list = []\n",
        "\n",
        "    for point in results.points:\n",
        "        metadata = {\n",
        "            \"score\": point.score,\n",
        "            \"text\": point.payload.get(\"text\", \"\"),\n",
        "            \"s3_path\": point.payload.get(\"s3_path\", \"\"),\n",
        "            \"file_name\": point.payload.get(\"file_name\", \"\"),\n",
        "            \"department\": point.payload.get(\"department\", \"\"),\n",
        "            \"top_keywords\": point.payload.get(\"top_keywords\", {}),\n",
        "        }\n",
        "        metadata_list.append(metadata)\n",
        "    print(metadata_list)\n",
        "    return metadata_list\n",
        "\n",
        "def build_prompt(query, top_chunks):\n",
        "    context = \"\"\n",
        "    source_refs = {}\n",
        "\n",
        "    for i, chunk in enumerate(top_chunks):\n",
        "        ref = f\"[{i+1}]\"\n",
        "        source = chunk.get(\"s3_path\", \"unknown\")\n",
        "        context += f\"{ref} ({source}):\\n{chunk['text']}\\n\\n\"\n",
        "        source_refs[ref] = source\n",
        "\n",
        "    prompt = f\"\"\"You are a helpful assistant. Use only the following context to answer the question.\n",
        "Cite sources using [1], [2], etc., based only on the exact chunks below. Do not make up citations. Do not include sources not explicitly mentioned.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "    return prompt, source_refs\n",
        "\n",
        "def rag_query(query, k=3):\n",
        "    start = time.time()\n",
        "    chunks = search_qdrant(query, k)\n",
        "    prompt, refs = build_prompt(query, chunks)\n",
        "\n",
        "    response = azure_client.chat.completions.create(\n",
        "        model=AZURE_DEPLOYMENT_NAME,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use only the following context to answer the question. Cite sources using [1], [2], etc., based only on the exact chunks below. Do not make up citations. Do not include sources not explicitly mentioned.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].message.content.strip()\n",
        "    latency = round((time.time() - start) * 1000, 2)\n",
        "\n",
        "    for ref in refs.values():\n",
        "        monitoring[\"access_count\"][ref] += 1\n",
        "    monitoring[\"latencies\"].append(latency)\n",
        "    monitoring[\"query_log\"].append({\n",
        "        \"query\": query,\n",
        "        \"sources\": list(refs.values()),\n",
        "        \"latency_ms\": latency\n",
        "    })\n",
        "\n",
        "    return answer, refs, latency, chunks\n",
        "\n",
        "\n",
        "# ------------------- UI -------------------\n",
        "st.set_page_config(page_title=\"RAG Chat with Citations\", layout=\"wide\")\n",
        "st.title(\"üí¨ RAG Assistant with Qdrant + Azure OpenAI\")\n",
        "\n",
        "st.markdown(\"Ask questions based on the preloaded document index.\")\n",
        "\n",
        "query = st.text_input(\"Enter your question here:\")\n",
        "\n",
        "if query:\n",
        "    with st.spinner(\"Searching and generating response...\"):\n",
        "        answer, refs, latency, retrieved_chunks = rag_query(query)\n",
        "\n",
        "        st.markdown(\"### üß† Answer\")\n",
        "        st.write(answer)\n",
        "\n",
        "        st.markdown(\"### üì¶ Retrieved Chunks\")\n",
        "\n",
        "        for i, chunk in enumerate(retrieved_chunks):\n",
        "            with st.expander(f\"[{i+1}] Source: {chunk['file_name']}\", expanded=True):\n",
        "                st.write(chunk[\"text\"])\n",
        "                st.caption(\n",
        "                    f\"üìÇ Department: `{chunk.get('department', 'unknown')}` | \"\n",
        "                    f\"üßæ File Path: {chunk.get('s3_path', 'N/A')}\"\n",
        "                )\n",
        "\n",
        "\n",
        "        st.markdown(\"### ‚è±Ô∏è Latency\")\n",
        "        st.write(f\"{latency} ms\")\n",
        "\n",
        "# ------------------- Sidebar: Monitoring -------------------\n",
        "st.sidebar.title(\"üìä Monitoring\")\n",
        "st.sidebar.write(f\"Total queries: {len(monitoring['query_log'])}\")\n",
        "if monitoring[\"latencies\"]:\n",
        "    st.sidebar.write(f\"Average latency: {np.mean(monitoring['latencies']):.2f} ms\")\n",
        "    st.sidebar.write(\"Top documents accessed:\")\n",
        "    top_sources = sorted(monitoring[\"access_count\"].items(), key=lambda x: x[1], reverse=True)\n",
        "    for src, count in top_sources:\n",
        "        st.sidebar.write(f\"‚Ä¢ {src}: {count}x\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIwMW6VIpvPw",
        "outputId": "d6d10698-2ac2-4612-8f1c-84ec1ebb944a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104.198.250.217\n",
            "/bin/bash: line 1: streamlit: command not found\n",
            "\u001b[1G\u001b[0K‚†ô^C\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com\n",
        "! streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import uuid, time\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import Distance, VectorParams, PointStruct, Filter, FieldCondition, MatchValue\n",
        "from openai import AzureOpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# ------------------- CONFIG -------------------\n",
        "QDRANT_HOST = \"54.152.12.154\"\n",
        "QDRANT_PORT = 6333\n",
        "COLLECTION = \"docs_chunks\"\n",
        "EMBED_DIM = 384\n",
        "\n",
        "# Azure OpenAI Config (replace with actual values)\n",
        "AZURE_OPENAI_ENDPOINT = \"https://ironclad-openai-001.openai.azure.com/\"\n",
        "AZURE_OPENAI_API_KEY = \"936856630b764210913d9a8fd6c8212b\"\n",
        "AZURE_DEPLOYMENT_NAME = \"gpt-4o\"\n",
        "def load_embedder():\n",
        "    return SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def load_azure_client():\n",
        "    return AzureOpenAI(\n",
        "        api_key=AZURE_OPENAI_API_KEY,\n",
        "        api_version=\"2023-05-15\",\n",
        "        azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
        "    )\n",
        "\n",
        "embed_model = load_embedder()\n",
        "azure_client = load_azure_client()\n",
        "import time\n",
        "def search_qdrant(query, k=3):\n",
        "    vec = embed_model.encode([query])[0]\n",
        "\n",
        "    results = client.query_points(\n",
        "        collection_name=COLLECTION,\n",
        "        query=vec,\n",
        "        limit=k,\n",
        "        with_payload=True,\n",
        "        timeout=120\n",
        "    )\n",
        "\n",
        "    metadata_list = []\n",
        "\n",
        "    for point in results.points:\n",
        "        metadata = {\n",
        "            \"score\": point.score,\n",
        "            \"text\": point.payload.get(\"text\", \"\"),\n",
        "            \"s3_path\": point.payload.get(\"s3_path\", \"\"),\n",
        "            \"file_name\": point.payload.get(\"file_name\", \"\"),\n",
        "            \"department\": point.payload.get(\"department\", \"\"),\n",
        "            \"top_keywords\": point.payload.get(\"top_keywords\", {}),\n",
        "        }\n",
        "        metadata_list.append(metadata)\n",
        "    print(metadata_list)\n",
        "    return metadata_list\n",
        "\n",
        "def build_prompt(query, top_chunks):\n",
        "    context = \"\"\n",
        "    source_refs = {}\n",
        "\n",
        "    for i, chunk in enumerate(top_chunks):\n",
        "        ref = f\"[{i+1}]\"\n",
        "        source = chunk.get(\"s3_path\", \"unknown\")\n",
        "        context += f\"{ref} ({source}):\\n{chunk['text']}\\n\\n\"\n",
        "        source_refs[ref] = source\n",
        "\n",
        "    prompt = f\"\"\"You are a helpful assistant. Use only the following context to answer the question.\n",
        "Cite sources using [1], [2], etc., based only on the exact chunks below. Do not make up citations. Do not include sources not explicitly mentioned.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "    return prompt, source_refs\n",
        "\n",
        "def rag_query(query, k=3):\n",
        "    start = time.time()\n",
        "    chunks = search_qdrant(query, k)\n",
        "    prompt, refs = build_prompt(query, chunks)\n",
        "\n",
        "    response = azure_client.chat.completions.create(\n",
        "        model=AZURE_DEPLOYMENT_NAME,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use only the following context to answer the question. Cite sources using [1], [2], etc., based only on the exact chunks below. Do not make up citations. Do not include sources not explicitly mentioned.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].message.content.strip()\n",
        "    print(answer)\n",
        "\n",
        "rag_query(\"what is the backend service that powers up aws lambda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1fwWah2LPYx",
        "outputId": "fedaba77-52c1-41cb-84bf-3f5dd926a077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'score': 0.466636, 'text': 'The seccomp-bpf proÔ¨Åle whitelists 24\\nsyscalls, each with additional argument Ô¨Åltering, and 30 ioctls\\n(of which 22 are required by KVM ioctl-based API). 4 Firecracker In Production\\n4.1 Inside A WS Lambda\\nLambda [51] is a compute service which runs functions in re-\\nsponse to events. Lambda offers a number of built-in language\\nruntimes (including Python, Java, NodeJS, and C#) which al-\\nlows functions to be provided as snippets of code implement-\\ning a language-speciÔ¨Åc runtime interface. A \"Hello, World!\" Lambda function can be implemented in as few as three lines\\nof Python or Javascript. It also supports an HTTP/REST run-\\ntime API, allowing programs which implement this API to\\nbe developed in any language, and provided either as bina-\\nries or a bundle alongside their language implementation. Lambda functions run within a sandbox, which provides a\\nminimal Linux userland and some common libraries and utili-\\nties. When Lambda functions are created, they are conÔ¨Ågured\\nwith a memory limit, and a maximum runtime to handle each\\nindividual event5. Events include those explicitly created by\\ncalling the Lambda Invoke API, from HTTP requests via\\nAWS‚Äôs Application Load Balancer and API Gateway, and\\nfrom integrations with other AWS services including storage\\n(S3), queue (SQS), streaming data (Kinesis) and database\\n(DynamoDB) services. Typical use-cases for AWS Lambda include backends for\\nIoT, mobile and web applications; request-response and event-\\n5As of early 2019, Lambda limits memory to less than 3GB and runtime\\nto 15 minutes, but we expect these limits to increase considerably over time. 424    17th USENIX Symposium on Networked Systems Design and Implementation USENIX Association\\nWorkersWorkersFrontendWorkerManagerPlacementWorkersFunction MetadataFigure 2: High-level architecture of AWS Lambda event path,\\nshowing control path (light lines) and data path (heavy lines)\\nsourced microservices; real-time streaming data processing;\\non-demand Ô¨Åle processing; and infrastructure automation. AWS markets Lambda as serverless compute, emphasizing\\nthat Lambda functions minimize operational and capacity\\nplanning work, and entirely eliminate per-server operations\\nfor most use-cases. Most typical deployments of Lambda\\nfunctions use them with other services in the AWS suite: S3,\\nSQS, DynamoDB and Elasticache are common companions. Lambda is a large-scale multi-tenant service, serving trillions\\nof events per month for hundreds of thousands of customers. 4.1.1 High-Level Architecture\\nFigure 2 presents a simpliÔ¨Åed view of the architecture of\\nLambda. Invoke trafÔ¨Åc arrives at the frontend via the Invoke\\nREST API, where requests are authenticated and checked\\nfor authorization, and function metadata is loaded. The fron-\\ntend is a scale-out shared-nothing Ô¨Çeet, with any frontend\\nable to handle trafÔ¨Åc for any function. The execution of the\\ncustomer code happens on the Lambda worker Ô¨Çeet, but to\\nimprove cache locality, enable connection re-use and amor-\\ntize the costs of moving and loading customer code, events\\nfor a single function are sticky-routed to as few workers as\\npossible. This sticky routing is the job of the Worker Man-\\nager, a custom high-volume (millions of requests per second)\\nlow-latency (<10ms 99.9th percentile latency) stateful router.', 's3_path': 's3://rag-vector-db-poc/FireCracker.pdf', 'file_name': 'FireCracker.pdf', 'department': 'root', 'top_keywords': {'api': 0.3078, 'aws': 0.3078, 'events': 0.2052, 'functions': 0.3078, 'lambda': 0.8208}}, {'score': 0.39250225, 'text': 'The Worker Manager replicates sticky routing information\\nfor a single function (or small group of functions) between\\na small number of hosts across diverse physical infrastruc-\\nture, to ensure high availability. Once the Worker Manager\\nhas identiÔ¨Åed which worker to run the code on, it advises the\\ninvoke service which sends the payload directly to the worker\\nto reduce round-trips. The Worker Manager and workers also\\nimplement a concurrency control protocol which resolves\\nthe race conditions created by large numbers of independent\\ninvoke services operating against a shared pool of workers. Each Lambda worker offers a number of slots, with each\\nslot providing a pre-loaded execution environment for a func-\\ntion. Slots are only ever used for a single function, and a\\nsingle concurrent invocation of that function, but are usedListing 1 Lambda function illustrating slot re-use. The re-\\nturned number will count up over many invokes. var i = 0;\\nexports.handler = async (event , context) => {\\nreturn i++;\\n};\\nCustomer CodeFirecrackerŒª ShimLinux KernelvirtioMicroManagerMicroVM ‚Äúslot‚ÄùMonitoring, Logging, etc. Figure 3: Architecture of the Lambda worker\\nfor many serial invocations of the function. The MicroVM\\nand the process the function is running in are both re-used, as\\nillustrated by Listing 1 which will return a series of increasing\\nnumbers when invoked with a stream of serial events. Where a slot is available for a function, the Worker Man-\\nager can simply perform its lightweight concurrency control\\nprotocol, and tell the frontend that the slot is available for\\nuse. Where no slot is available, either because none exists\\nor because trafÔ¨Åc to a function has increased to require addi-\\ntional slots, the Worker Manager calls the Placement service\\nto request that a new slot is created for the function. The\\nPlacement service in turn optimizes the placement of slots\\nfor a single function across the worker Ô¨Çeet, ensuring that the\\nutilization of resources including CPU, memory, network, and\\nstorage is even across the Ô¨Çeet and the potential for correlated\\nresource allocation on each individual worker is minimized. Once this optimization is complete ‚Äî a task which typically\\ntakes less than 20ms ‚Äî the Placement service contacts a\\nworker to request that it creates a slot for a function. The\\nPlacement service uses a time-based lease [17] protocol to\\nlease the resulting slot to the Worker Manager, allowing it to\\nmake autonomous decisions for a Ô¨Åxed period of time. The Placement service remains responsible for slots, in-\\ncluding limiting their lifetime (in response to the life cycle of\\nthe worker hosts), terminating slots which have become idle\\nor redundant, managing software updates, and other similar\\nactivities. Using a lease protocol allows the system to both\\nmaintain efÔ¨Åcient sticky routing (and hence locality) and have\\nclear ownership of resources. As part of its optimization re-\\nsponsibilities, the placement service also consumes load and\\nhealth data for each slot in each worker.', 's3_path': 's3://rag-vector-db-poc/FireCracker.pdf', 'file_name': 'FireCracker.pdf', 'department': 'root', 'top_keywords': {'function': 0.4716, 'placement': 0.3001, 'service': 0.3001, 'slot': 0.4287, 'worker': 0.6431}}, {'score': 0.3560284, 'text': 'Directions we are interested in include: increasing density\\n(especially memory deduplication) without sacriÔ¨Åcing isola-\\ntion against architectural and microarchitectural side-channel\\nattacks; compute hardware optimized for high-density multi-\\ntenancy; high-density host bypass for networking, storage and\\naccelerator hardware; reducing the size of the virtualization\\ntrusted compute base; and dramatically reducing startup and\\nworkload switching costs. The hardware, user expectations,\\nand threat landscape around running multitenant container\\nand function workloads are changing fast. Perhaps faster than\\nat any other point in the last decade. We are excited to con-\\ntinue to work with the research and open source communities\\nto meet these challenges. 7 Acknowledgements\\nThe Firecracker team at AWS, and the open source commu-\\nnity, made Firecracker and this paper possible. Production\\nexperience and feedback from the AWS Lambda and Fargate\\nteams was invaluable. Thanks to Tim Harris, Andy WarÔ¨Åeld,\\nRadu Weiss and David R. Richardson for their valuable feed-\\nback on the paper. References\\n[1]Istemi Ekin Akkus, Ruichuan Chen, Ivica Rimac,\\nManuel Stein, Klaus Satzke, Andre Beck, Paarijaat\\n430    17th USENIX Symposium on Networked Systems Design and Implementation USENIX Association\\nAditya, and V olker Hilt. Sand: Towards high-\\nperformance serverless computing. In 2018 USENIX\\nAnnual Technical Conference (USENIX ATC 18) , pages\\n923‚Äì935, 2018. [2]Alejandro Cabrera Aldaya, Billy Bob Brumley, Sohaib\\nul Hassan, Cesar Pereida Garc√≠a, and Nicola Tuveri. Port\\ncontention for fun and proÔ¨Åt. IACR Cryptology ePrint\\nArchive , 2018:1060, 2018. [3]Jens Axboe. Fio: Flexible i/o tester, 2019. URL: https:\\n//github.com/axboe/fio/ . [4]Microsoft Azure. Azure functions, 2019. URL:\\nhttps://azure.microsoft.com/en-us/services/\\nfunctions/ . [5]Paul Barham, Boris Dragovic, Keir Fraser, Steven Hand,\\nTim Harris, Alex Ho, Rolf Neugebauer, Ian Pratt, and\\nAndrew WarÔ¨Åeld. Xen and the art of virtualization. In\\nACM SIGOPS operating systems review , volume 37,\\npages 164‚Äì177. ACM, 2003. [6]Andrew Baumann, Dongyoon Lee, Pedro Fonseca,\\nLisa Glendenning, Jacob R. Lorch, Barry Bond,\\nReuben Olinsky, and Galen C. Hunt. Composing\\nos extensions safely and efÔ¨Åciently with bascule. InProceedings of the 8th ACM European Confer-\\nence on Computer Systems , EuroSys ‚Äô13, pages\\n239‚Äì252, New York, NY , USA, 2013. ACM. URL:\\nhttp://doi.acm.org/10.1145/2465351.2465375 ,\\ndoi:10.1145/2465351.2465375 . [7]Fabrice Bellard. Qemu, a fast and portable dynamic\\ntranslator. In USENIX Annual Technical Conference,\\nFREENIX Track , volume 41, page 46, 2005. [8]Paolo Bonzini. Minimal x86 Ô¨Årmware for booting linux\\nkernels, 2019. URL: https://github.com/bonzini/\\nqboot . [9]Reto Buerki and Adrian-Ken Rueegsegger. Muen-an\\nx86/64 separation kernel for high assurance. University\\nof Applied Sciences Rapperswil (HSR), Tech. Rep , 2013. [10] Claudio Canella, Jo Van Bulck, Michael Schwarz,\\nMoritz Lipp, Benjamin von Berg, Philipp Ortner, Frank\\nPiessens, Dmitry Evtyushkin, and Daniel Gruss. A sys-\\ntematic evaluation of transient execution attacks and\\ndefenses. arXiv preprint arXiv:1811.05441 , 2018. [11] Google Cloud. KNative, 2018. URL: https://cloud. google.com/knative/ . [12] Sadjad Fouladi, Francisco Romero, Dan Iter, Qian\\nLi, Shuvo Chatterjee, Christos Kozyrakis, Matei Za-\\nharia, and Keith Winstein. From laptop to lambda:Outsourcing everyday jobs to thousands of tran-\\nsient functional containers. In 2019 USENIX An-\\nnual Technical Conference (USENIX ATC 19) , pages\\n475‚Äì488, Renton, WA, July 2019.', 's3_path': 's3://rag-vector-db-poc/FireCracker.pdf', 'file_name': 'FireCracker.pdf', 'department': 'root', 'top_keywords': {'2018': 0.4743, '2019': 0.3953, 'acm': 0.3953, 'url': 0.3953, 'usenix': 0.5534}}]\n",
            "AWS Lambda is powered by a backend service involving a large-scale multi-tenant architecture, which includes various components such as the frontend, worker fleet, Worker Manager, and Placement service. The frontend handles invoke traffic, authentication, and authorization, while the worker fleet executes customer code. The Worker Manager manages sticky routing and concurrency control, and the Placement service optimizes slot creation across the worker fleet [1], [2].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cA7HbtxnU1ut"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8fbb0099edfc4ba9bf3d396ff63fdee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80adcfc69f974d249dcc72828a45d41c",
              "IPY_MODEL_064adf7732fd48c4a9984c4aa5476c35",
              "IPY_MODEL_b0ae3ca6f66a49c59ecfb31b974c3dff"
            ],
            "layout": "IPY_MODEL_df35626a32274290b233eed748c56a08"
          }
        },
        "80adcfc69f974d249dcc72828a45d41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fa320b89fef4b939ed7087dfa69e841",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7c37effbe14645b3b5f099873c09c0de",
            "value": "Batches:‚Äá100%"
          }
        },
        "064adf7732fd48c4a9984c4aa5476c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe8241a42eb34deaa27b286b947656cf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21bfb45891c8412bac1535cb85652c82",
            "value": 1
          }
        },
        "b0ae3ca6f66a49c59ecfb31b974c3dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fde048cc7f5a46be917a4e491256ac2f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5e53585248774ddbb1139d62bf26e22f",
            "value": "‚Äá1/1‚Äá[00:07&lt;00:00,‚Äá‚Äá7.18s/it]"
          }
        },
        "df35626a32274290b233eed748c56a08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa320b89fef4b939ed7087dfa69e841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c37effbe14645b3b5f099873c09c0de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe8241a42eb34deaa27b286b947656cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21bfb45891c8412bac1535cb85652c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fde048cc7f5a46be917a4e491256ac2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e53585248774ddbb1139d62bf26e22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28f9f358b827478abd19ab850d733b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_075eda04743748579d2ae353863e38ef",
              "IPY_MODEL_68845fac2626420e89ec39226de33525",
              "IPY_MODEL_e3631036bc034f26874cad147c9bb738"
            ],
            "layout": "IPY_MODEL_b13313670cce43d6aa2a69efb844285a"
          }
        },
        "075eda04743748579d2ae353863e38ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c0a8e836a864502abfa49cb2156deba",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_578d211df9fb47bb98bcb19d0397eeee",
            "value": "Batches:‚Äá100%"
          }
        },
        "68845fac2626420e89ec39226de33525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e19cd05cbb142d4873a206a30e929de",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c97fe14fbc3e4cffbfd94b95ed78148b",
            "value": 1
          }
        },
        "e3631036bc034f26874cad147c9bb738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50bf1f94336849df821cdca00fec3eec",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_256b2ed0925c47aabcbccdc444265ede",
            "value": "‚Äá1/1‚Äá[00:03&lt;00:00,‚Äá‚Äá3.99s/it]"
          }
        },
        "b13313670cce43d6aa2a69efb844285a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c0a8e836a864502abfa49cb2156deba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "578d211df9fb47bb98bcb19d0397eeee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e19cd05cbb142d4873a206a30e929de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c97fe14fbc3e4cffbfd94b95ed78148b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50bf1f94336849df821cdca00fec3eec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "256b2ed0925c47aabcbccdc444265ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d628c242a43459ba7f7e2694a54dfb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11004b66a7d84e7ab2cf66fc45bce8b3",
              "IPY_MODEL_73114c4a115b4ff283903126aa5f5f1e",
              "IPY_MODEL_4b665333955047388b1014d78c09dace"
            ],
            "layout": "IPY_MODEL_3ba00ba9adb34357897803dbd5912e0e"
          }
        },
        "11004b66a7d84e7ab2cf66fc45bce8b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f112e797094046ab85572946c167983e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f3432e8539f7457e8e554b3f51c74a7e",
            "value": "Batches:‚Äá100%"
          }
        },
        "73114c4a115b4ff283903126aa5f5f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14f42cbac9eb4e24b57ae0f4ed6a3df4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_843f5d88537547088deb2389e8c0d8c5",
            "value": 1
          }
        },
        "4b665333955047388b1014d78c09dace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e23c77c24f2841a58e586d16dae38d26",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_06be448d605e4b07ab6c822f24ea27a2",
            "value": "‚Äá1/1‚Äá[00:06&lt;00:00,‚Äá‚Äá6.19s/it]"
          }
        },
        "3ba00ba9adb34357897803dbd5912e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f112e797094046ab85572946c167983e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3432e8539f7457e8e554b3f51c74a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14f42cbac9eb4e24b57ae0f4ed6a3df4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "843f5d88537547088deb2389e8c0d8c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e23c77c24f2841a58e586d16dae38d26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06be448d605e4b07ab6c822f24ea27a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f36ff66f2f664a65b427cce1e23d0f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_820a460ae005474bb3f508f721b25e5f",
              "IPY_MODEL_cf3fb69ffee3424ea058665e1758861b",
              "IPY_MODEL_584d12678b794116bc781bc1885951fd"
            ],
            "layout": "IPY_MODEL_39c341dd244d477f93479b756a52eb81"
          }
        },
        "820a460ae005474bb3f508f721b25e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1bf12fb765840219cc655c508e47a41",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4066722238f74af088d67977dec41e2a",
            "value": "Batches:‚Äá100%"
          }
        },
        "cf3fb69ffee3424ea058665e1758861b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6c0927d64914e43b8014e3acd4ce4b3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f703951870a4d4581f58cb98ba38766",
            "value": 1
          }
        },
        "584d12678b794116bc781bc1885951fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f25cc24bec584e32bb3f64330a158950",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_90aa47215a4042b28f89f29a37bc781c",
            "value": "‚Äá1/1‚Äá[00:01&lt;00:00,‚Äá‚Äá1.32s/it]"
          }
        },
        "39c341dd244d477f93479b756a52eb81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1bf12fb765840219cc655c508e47a41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4066722238f74af088d67977dec41e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6c0927d64914e43b8014e3acd4ce4b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f703951870a4d4581f58cb98ba38766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f25cc24bec584e32bb3f64330a158950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90aa47215a4042b28f89f29a37bc781c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87ccbc78d61f479b805a61d00d6f6c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ceecc08123934525a786fdaecc909f27",
              "IPY_MODEL_455bddad12cb4d328476cf89ad29bc86",
              "IPY_MODEL_553ec0f51b2f4515ab80762a88386319"
            ],
            "layout": "IPY_MODEL_ba8865c33f154594836d890e00e833c2"
          }
        },
        "ceecc08123934525a786fdaecc909f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_894b0c5d6336457780479d446274bd94",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0a49dc8ee82246c4bc133b2c0b3339a9",
            "value": "Batches:‚Äá100%"
          }
        },
        "455bddad12cb4d328476cf89ad29bc86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83ff4468a6854ae3bedd8be0052bcc24",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6011f247441c4c85a50b0f71d15b70be",
            "value": 1
          }
        },
        "553ec0f51b2f4515ab80762a88386319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8ea60fc89974be2ae8e0c7d41c3b1d6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6dd69386a9ac440fb4101ffb03c5247c",
            "value": "‚Äá1/1‚Äá[00:02&lt;00:00,‚Äá‚Äá2.07s/it]"
          }
        },
        "ba8865c33f154594836d890e00e833c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "894b0c5d6336457780479d446274bd94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a49dc8ee82246c4bc133b2c0b3339a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83ff4468a6854ae3bedd8be0052bcc24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6011f247441c4c85a50b0f71d15b70be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8ea60fc89974be2ae8e0c7d41c3b1d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dd69386a9ac440fb4101ffb03c5247c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "795eca22e31648d8a04df0daa4b05a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cee22c0ee94047339024378ba7371684",
              "IPY_MODEL_2038bdf2485d46baae2f72f5017cda5a",
              "IPY_MODEL_5b2c35b463534a7fae3a4ad957f20ebf"
            ],
            "layout": "IPY_MODEL_5bc1482daa2441e8b9152080ac56b1da"
          }
        },
        "cee22c0ee94047339024378ba7371684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a0fa4cc583948afa85eb97614bcef57",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_180c71dd5bec4e46b82648b390532a6b",
            "value": "Batches:‚Äá100%"
          }
        },
        "2038bdf2485d46baae2f72f5017cda5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b45e41764a054d17a7cfeb1f4e038a85",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a78048c2d6c4e818478376486200e25",
            "value": 1
          }
        },
        "5b2c35b463534a7fae3a4ad957f20ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_555bd020baea417e9b711411282fd9e2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_eb32c83e4fa64dab87e93be128bb6f47",
            "value": "‚Äá1/1‚Äá[00:02&lt;00:00,‚Äá‚Äá2.76s/it]"
          }
        },
        "5bc1482daa2441e8b9152080ac56b1da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a0fa4cc583948afa85eb97614bcef57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "180c71dd5bec4e46b82648b390532a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b45e41764a054d17a7cfeb1f4e038a85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a78048c2d6c4e818478376486200e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "555bd020baea417e9b711411282fd9e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb32c83e4fa64dab87e93be128bb6f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91efd31fec3f484a8ca9b27c83943314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22eeb8ce585c4563be480dde038e98f9",
              "IPY_MODEL_298547ba098a4a999651f4867c0cce74",
              "IPY_MODEL_45641ec6e9d742198b1be83eeadcac30"
            ],
            "layout": "IPY_MODEL_b94aeed5822c450bb6be9257b16a8cc4"
          }
        },
        "22eeb8ce585c4563be480dde038e98f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d7f4689607e4a678cae270de14e4010",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_878698308fd14adfad1dd00265502074",
            "value": "Batches:‚Äá100%"
          }
        },
        "298547ba098a4a999651f4867c0cce74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b113a9be42fd4044b094ad463def47b2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ec6dfb062144a43af3d72901795a0e9",
            "value": 1
          }
        },
        "45641ec6e9d742198b1be83eeadcac30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85a756d65f844e53b370a43f8fab5efd",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0de0a9a8f30540c3a7ce8a3e7f302cbd",
            "value": "‚Äá1/1‚Äá[00:02&lt;00:00,‚Äá‚Äá2.52s/it]"
          }
        },
        "b94aeed5822c450bb6be9257b16a8cc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d7f4689607e4a678cae270de14e4010": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "878698308fd14adfad1dd00265502074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b113a9be42fd4044b094ad463def47b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ec6dfb062144a43af3d72901795a0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85a756d65f844e53b370a43f8fab5efd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0de0a9a8f30540c3a7ce8a3e7f302cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "334ff0f080714157a9a75ac40d6444fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_575c32a798bd40959531804c0d9b4d19",
              "IPY_MODEL_1337fb4dac504af0bff4652935c23454",
              "IPY_MODEL_3f99f58c47794161907c36b7177f9649"
            ],
            "layout": "IPY_MODEL_2cf8f0f84d8247e8aa88d8a9bc62b175"
          }
        },
        "575c32a798bd40959531804c0d9b4d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df3d109cac1b47d6962bad51b125dcb0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ce813e19c9ef4c93aabb799a6393b941",
            "value": "Batches:‚Äá100%"
          }
        },
        "1337fb4dac504af0bff4652935c23454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e0515190dd541b684c6f3559e93aa5f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_532d9fbfa6044a46a50c9625d68fd602",
            "value": 1
          }
        },
        "3f99f58c47794161907c36b7177f9649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_757672ff1224495bb7d381d0a6d61d0b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2995a6cf0c224ab39bb1be8ad8c858d4",
            "value": "‚Äá1/1‚Äá[00:00&lt;00:00,‚Äá‚Äá1.14it/s]"
          }
        },
        "2cf8f0f84d8247e8aa88d8a9bc62b175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df3d109cac1b47d6962bad51b125dcb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce813e19c9ef4c93aabb799a6393b941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e0515190dd541b684c6f3559e93aa5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "532d9fbfa6044a46a50c9625d68fd602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "757672ff1224495bb7d381d0a6d61d0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2995a6cf0c224ab39bb1be8ad8c858d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4787153f2a954929b1bbf2745fc35632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb8db9b34d0141a39bca79d3bf44691d",
              "IPY_MODEL_ed4ff0f10f14450a8b77295fd08947d3",
              "IPY_MODEL_28eda06ea6f147399725add40e161b2f"
            ],
            "layout": "IPY_MODEL_cf1692b8c17a4f06b1d4c353c69f58bc"
          }
        },
        "fb8db9b34d0141a39bca79d3bf44691d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3fd07f6a1074bda9cb05b90d0b44638",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2472ed2b530a4f9a8a27c08ce8a72093",
            "value": "Batches:‚Äá100%"
          }
        },
        "ed4ff0f10f14450a8b77295fd08947d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fc9199048ff40e1aac99a08010a84d9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d84b83f8b51b4fc89647097dc138a9af",
            "value": 1
          }
        },
        "28eda06ea6f147399725add40e161b2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24c5f93dee7c41f1b32a06a94ab83ce7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5793332c630d4ae09587f4b388304fff",
            "value": "‚Äá1/1‚Äá[00:02&lt;00:00,‚Äá‚Äá2.56s/it]"
          }
        },
        "cf1692b8c17a4f06b1d4c353c69f58bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3fd07f6a1074bda9cb05b90d0b44638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2472ed2b530a4f9a8a27c08ce8a72093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fc9199048ff40e1aac99a08010a84d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84b83f8b51b4fc89647097dc138a9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24c5f93dee7c41f1b32a06a94ab83ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5793332c630d4ae09587f4b388304fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "755efbbb56f84b56a8bed549a1bfd46c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_305b40f094d34760ae3b236508d8bc4d",
              "IPY_MODEL_0ac6970cd76a4992a83023c8f0aa6793",
              "IPY_MODEL_368c1fa641d6441bbbec5a1df45690a8"
            ],
            "layout": "IPY_MODEL_edd92632c0a24631ab0fc2bdaca61861"
          }
        },
        "305b40f094d34760ae3b236508d8bc4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e2d7488ab6648b0af1c86b84b31aac4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_06bbf254cd6a44fbb628051be546582a",
            "value": "Batches:‚Äá100%"
          }
        },
        "0ac6970cd76a4992a83023c8f0aa6793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3069b3cad5594f4aa50f659b092f2998",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17eec0c390094d9282e985e26dc67800",
            "value": 1
          }
        },
        "368c1fa641d6441bbbec5a1df45690a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0086269d332e4eb7b9ce2471d995ea80",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3dd9dc336f94457085562163282a77b0",
            "value": "‚Äá1/1‚Äá[00:02&lt;00:00,‚Äá‚Äá2.05s/it]"
          }
        },
        "edd92632c0a24631ab0fc2bdaca61861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2d7488ab6648b0af1c86b84b31aac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06bbf254cd6a44fbb628051be546582a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3069b3cad5594f4aa50f659b092f2998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17eec0c390094d9282e985e26dc67800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0086269d332e4eb7b9ce2471d995ea80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dd9dc336f94457085562163282a77b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae2e344dc41d47d180e07948fa0a5f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25394831ad0d4e2bb96c63b4c3041f22",
              "IPY_MODEL_2d63d731489d4d6ea3f950b216ed3172",
              "IPY_MODEL_d17758c7e33249a0bb77a2347c60f814"
            ],
            "layout": "IPY_MODEL_1f37a0decc64481aaa87efe732e20412"
          }
        },
        "25394831ad0d4e2bb96c63b4c3041f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec8c1d6eafa04290ab6919d23f68ca8f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8fece7384d7349229bf0ae48f28cd970",
            "value": "Batches:‚Äá100%"
          }
        },
        "2d63d731489d4d6ea3f950b216ed3172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4aa28ea041140fc9ffbdc9f4e2ca3ba",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28dc0b070524423997ac3209b3a64caa",
            "value": 1
          }
        },
        "d17758c7e33249a0bb77a2347c60f814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bc6d465e2914c3486b93414f2385156",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ab98f14d9730407e832404fb8b52fe8e",
            "value": "‚Äá1/1‚Äá[00:03&lt;00:00,‚Äá‚Äá3.53s/it]"
          }
        },
        "1f37a0decc64481aaa87efe732e20412": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec8c1d6eafa04290ab6919d23f68ca8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fece7384d7349229bf0ae48f28cd970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4aa28ea041140fc9ffbdc9f4e2ca3ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28dc0b070524423997ac3209b3a64caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bc6d465e2914c3486b93414f2385156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab98f14d9730407e832404fb8b52fe8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2b57082e9d04b898fac4dbb27dda531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bb29c3b6eec48259442159c60641db8",
              "IPY_MODEL_47548bcb2380443d8cef30c7f982785b",
              "IPY_MODEL_5f5796f661e24fe59e883df6efcb7424"
            ],
            "layout": "IPY_MODEL_f665b6ca2ad24d4a8c1afdc6d8982085"
          }
        },
        "2bb29c3b6eec48259442159c60641db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05d1c714029049b2be2f2e5fe7f7b61b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0900a283f8344f2eb147fa1520862883",
            "value": "Batches:‚Äá100%"
          }
        },
        "47548bcb2380443d8cef30c7f982785b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8cd211a70434064926219ae223736d2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92eb9d6035b044e2947a6f7f5fd6c6a1",
            "value": 1
          }
        },
        "5f5796f661e24fe59e883df6efcb7424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dcd70cb81d04c2a99d16efdd5c9a746",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f3b2ae76ecdc4de0992a61adccbaf603",
            "value": "‚Äá1/1‚Äá[00:00&lt;00:00,‚Äá‚Äá1.89it/s]"
          }
        },
        "f665b6ca2ad24d4a8c1afdc6d8982085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05d1c714029049b2be2f2e5fe7f7b61b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0900a283f8344f2eb147fa1520862883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8cd211a70434064926219ae223736d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92eb9d6035b044e2947a6f7f5fd6c6a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5dcd70cb81d04c2a99d16efdd5c9a746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3b2ae76ecdc4de0992a61adccbaf603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "feb2e6afa7494f3389c95f8f019de904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c08b1cdeced4fdb987f2fdb5ba05fb2",
              "IPY_MODEL_9fca02d91ef7446585da4aa6c68e1d98",
              "IPY_MODEL_8a8fcf087e934e4e9a00a8de5089658b"
            ],
            "layout": "IPY_MODEL_7f9b49e381f446b79d051e5f3a3f67f5"
          }
        },
        "5c08b1cdeced4fdb987f2fdb5ba05fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd84414920604f1194215c3db63d0605",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_103fee5e797d4aac83a4523d99a3a155",
            "value": "Batches:‚Äá100%"
          }
        },
        "9fca02d91ef7446585da4aa6c68e1d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4207997a38b344c0b4f17dd527fb5f22",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0173f36f61c47658c0ea8ae2ba75835",
            "value": 1
          }
        },
        "8a8fcf087e934e4e9a00a8de5089658b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71430a55b4ae494b91b1ddcbfa080d42",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6711d2c5bd804877b18ba99584da9116",
            "value": "‚Äá1/1‚Äá[00:04&lt;00:00,‚Äá‚Äá4.47s/it]"
          }
        },
        "7f9b49e381f446b79d051e5f3a3f67f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd84414920604f1194215c3db63d0605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "103fee5e797d4aac83a4523d99a3a155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4207997a38b344c0b4f17dd527fb5f22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0173f36f61c47658c0ea8ae2ba75835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71430a55b4ae494b91b1ddcbfa080d42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6711d2c5bd804877b18ba99584da9116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ffcc6e266af4cd5ac1e5ad2a1ceeb2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08b79ff8ba8b4d15a9c3bf1a611eafde",
              "IPY_MODEL_dfd6c3a387324751b53532c575b6b37c",
              "IPY_MODEL_0ed45a1dfd5047038f11005deb9c36be"
            ],
            "layout": "IPY_MODEL_11de4a75fec6444aa24a5c44708e4c76"
          }
        },
        "08b79ff8ba8b4d15a9c3bf1a611eafde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32f04950e5fa49b59c3848e7bcf62c7c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0cf0b91839b841a5ab20a1aba68ce3ee",
            "value": "Batches:‚Äá100%"
          }
        },
        "dfd6c3a387324751b53532c575b6b37c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_100380cb8f534310901078fc458e345e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebc3ec2bb5a74c1297164b5762e84b6d",
            "value": 1
          }
        },
        "0ed45a1dfd5047038f11005deb9c36be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9c95a63b33b490ca66a29f770a726b2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_63fddacf860c43dda5b76e63321d165b",
            "value": "‚Äá1/1‚Äá[00:02&lt;00:00,‚Äá‚Äá2.32s/it]"
          }
        },
        "11de4a75fec6444aa24a5c44708e4c76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32f04950e5fa49b59c3848e7bcf62c7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cf0b91839b841a5ab20a1aba68ce3ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "100380cb8f534310901078fc458e345e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebc3ec2bb5a74c1297164b5762e84b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9c95a63b33b490ca66a29f770a726b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63fddacf860c43dda5b76e63321d165b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}